{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9b2c2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c784950",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the dataset which is the output of TOPSIS\n",
    "step10=pd.read_csv('../data/football_step10.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eafff310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unnecessary Date column\n",
    "step10.drop(\"Date\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "940f4c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week_ofday</th>\n",
       "      <th>League_ID</th>\n",
       "      <th>League</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>spi_1</th>\n",
       "      <th>spi_2</th>\n",
       "      <th>prob_1</th>\n",
       "      <th>...</th>\n",
       "      <th>DETAIL_spi_y</th>\n",
       "      <th>OVRL_spi_y</th>\n",
       "      <th>Avg_Age_y</th>\n",
       "      <th>Total_marketcap_y</th>\n",
       "      <th>Value_per_year_y</th>\n",
       "      <th>point_team1</th>\n",
       "      <th>point_team2</th>\n",
       "      <th>rolling5_team1</th>\n",
       "      <th>rolling5_team2</th>\n",
       "      <th>scor_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1854</td>\n",
       "      <td>Serie A</td>\n",
       "      <td>Verona</td>\n",
       "      <td>Roma</td>\n",
       "      <td>58.27</td>\n",
       "      <td>73.95</td>\n",
       "      <td>0.2429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618281</td>\n",
       "      <td>0.367339</td>\n",
       "      <td>26.00</td>\n",
       "      <td>365000000.0</td>\n",
       "      <td>0.129278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1854</td>\n",
       "      <td>Serie A</td>\n",
       "      <td>Monza</td>\n",
       "      <td>Bologna</td>\n",
       "      <td>52.43</td>\n",
       "      <td>54.39</td>\n",
       "      <td>0.3983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320189</td>\n",
       "      <td>0.339007</td>\n",
       "      <td>25.50</td>\n",
       "      <td>125000000.0</td>\n",
       "      <td>0.038690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1869</td>\n",
       "      <td>LaLiga</td>\n",
       "      <td>Elche</td>\n",
       "      <td>Getafe</td>\n",
       "      <td>52.69</td>\n",
       "      <td>62.53</td>\n",
       "      <td>0.3575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112096</td>\n",
       "      <td>0.208027</td>\n",
       "      <td>27.80</td>\n",
       "      <td>137000000.0</td>\n",
       "      <td>0.618056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1869</td>\n",
       "      <td>LaLiga</td>\n",
       "      <td>Osasuna</td>\n",
       "      <td>Real Valladolid</td>\n",
       "      <td>67.77</td>\n",
       "      <td>58.91</td>\n",
       "      <td>0.5122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235717</td>\n",
       "      <td>0.280795</td>\n",
       "      <td>28.30</td>\n",
       "      <td>59000000.0</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1843</td>\n",
       "      <td>Ligue 1</td>\n",
       "      <td>Auxerre</td>\n",
       "      <td>AC Ajaccio</td>\n",
       "      <td>46.20</td>\n",
       "      <td>52.39</td>\n",
       "      <td>0.3827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255741</td>\n",
       "      <td>0.268034</td>\n",
       "      <td>25.55</td>\n",
       "      <td>50000000.0</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  Week_ofday  League_ID   League    team1            team2  \\\n",
       "0  2022     10           0       1854  Serie A   Verona             Roma   \n",
       "1  2022     10           0       1854  Serie A    Monza          Bologna   \n",
       "2  2022     10           0       1869   LaLiga    Elche           Getafe   \n",
       "3  2022     10           6       1869   LaLiga  Osasuna  Real Valladolid   \n",
       "4  2022     10           6       1843  Ligue 1  Auxerre       AC Ajaccio   \n",
       "\n",
       "   spi_1  spi_2  prob_1  ...  DETAIL_spi_y  OVRL_spi_y  Avg_Age_y  \\\n",
       "0  58.27  73.95  0.2429  ...      0.618281    0.367339      26.00   \n",
       "1  52.43  54.39  0.3983  ...      0.320189    0.339007      25.50   \n",
       "2  52.69  62.53  0.3575  ...      0.112096    0.208027      27.80   \n",
       "3  67.77  58.91  0.5122  ...      0.235717    0.280795      28.30   \n",
       "4  46.20  52.39  0.3827  ...      0.255741    0.268034      25.55   \n",
       "\n",
       "   Total_marketcap_y  Value_per_year_y  point_team1  point_team2  \\\n",
       "0        365000000.0          0.129278          0.0          4.0   \n",
       "1        125000000.0          0.038690          0.0          4.0   \n",
       "2        137000000.0          0.618056          0.0          4.0   \n",
       "3         59000000.0          0.603175          3.0          0.0   \n",
       "4         50000000.0          0.320000          3.0          0.0   \n",
       "\n",
       "   rolling5_team1  rolling5_team2  scor_diff  \n",
       "0             3.0            13.5         -2  \n",
       "1             6.0             1.5         -1  \n",
       "2             2.0             7.0         -1  \n",
       "3             9.0             5.5          2  \n",
       "4             5.0             9.5          1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chech the dataframe\n",
    "step10.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5445cf",
   "metadata": {},
   "source": [
    "# Win-Lose Profit Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccb5d322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Calculate the profit/loss in the situtation where $100 staked to all the matches\n",
    "def calculate_value_winlose(row):\n",
    "    if row['True_False'] == 1:\n",
    "        if row['scor_diff'] == 0:\n",
    "            return 100 * (row['odds_0'] - 1)\n",
    "        elif row['scor_diff'] == 1:\n",
    "            return 100 * (row['odds_1'] - 1)\n",
    "        elif row['scor_diff'] == 2:\n",
    "            return 100 * (row['odds_2'] - 1)\n",
    "    elif row['True_False'] == 0:\n",
    "        return -100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdef215",
   "metadata": {},
   "source": [
    "# Draw No Bet Profit Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "725580e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Calculate the profit/loss in the situtation where $100 staked to \n",
    "#all the matches that are predicted 1 or 2 as the result.\n",
    "def calculate_value_dnb(row):\n",
    "    if row['True_False'] == 1:\n",
    "        if row['scor_diff'] < 0:\n",
    "            return 100 * (row['dnb_odds_2'] - 1)\n",
    "        \n",
    "        elif row['scor_diff'] > 0:\n",
    "            return 100 * (row['dnb_odds_1'] - 1)\n",
    "        \n",
    "    elif row['True_False'] == 0:\n",
    "        return -100\n",
    "    \n",
    "    elif row['True_False']==2:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376263d3",
   "metadata": {},
   "source": [
    "# Derive the Odds and Draw no bet Odds from probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4249e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD BETTING ODD COLUMNS TO Calculate potential profits\n",
    "\n",
    "# Calculating the betting odds\n",
    "\n",
    "def probability_to_reg_dnb_odds(df):\n",
    "    # Calculate the regular odds for team1, team2, and draw\n",
    "    \n",
    "    df1=df.copy()\n",
    "    odds_1 = 1 / df1['prob_1'] \n",
    "    odds_2 = 1 / df1['prob_2']\n",
    "    odds_0 = 1 / df1['prob_0']\n",
    "    \n",
    "    df1['odds_1'] = odds_1\n",
    "    df1['odds_2'] = odds_2\n",
    "    df1['odds_0'] = odds_0\n",
    "    \n",
    "    # Calculate the \"Draw No Bet\" odds for team1 and team2\n",
    "    df1['dnb_odds_1'] = odds_1 * (1 - df1['prob_0']) # team1-odd\n",
    "    df1['dnb_odds_2'] = odds_2 * (1 - df1['prob_0']) # team2-odd\n",
    "    \n",
    "    df1.drop(['prob_1','prob_2','prob_0'],axis=1, inplace=True)\n",
    "\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8568c7",
   "metadata": {},
   "source": [
    "# MODEL A: DRAW NO BET Profits by Score Difference Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "286d0e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model_draw_no_bet(df):\n",
    "    #copy the df just in case\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    #Drop unnecessary columns\n",
    "    df_processed.drop(['League', 'team1', 'team2','point_team1', 'point_team2','spi_1','spi_2'], axis=1, inplace=True)\n",
    "    \n",
    "    #Alter extreme values to be able to predict with the classification models\n",
    "    df_processed.loc[df_processed['scor_diff'] == 9, 'scor_diff'] = 8\n",
    "    df_processed.loc[df_processed['scor_diff'] == -9, 'scor_diff'] = -8\n",
    "    \n",
    "    #Define feature and target columns\n",
    "    X = df_processed.drop(['scor_diff'], axis=1)\n",
    "    y = df_processed['scor_diff']\n",
    "\n",
    "    # Sort the DataFrame by date columns in descending order\n",
    "    df_sorted = df_processed.sort_values(by=['Year', 'Month', 'Week_ofday'], ascending=True)\n",
    "    \n",
    "\n",
    "    # Calculate the indices for the train-test split\n",
    "    train_size = int(0.75 * len(df_sorted))\n",
    "    train_indices = df_sorted.index[:train_size]\n",
    "    test_indices = df_sorted.index[train_size:]\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train = X.loc[train_indices]\n",
    "    X_test = X.loc[test_indices]\n",
    "    y_train = y.loc[train_indices]\n",
    "    y_test = y.loc[test_indices]\n",
    "\n",
    "    # Create a list of all possible combinations of hyperparameters\n",
    "    scaling = [MinMaxScaler(), StandardScaler(), RobustScaler()]\n",
    "    classifier = [\n",
    "        KNeighborsClassifier(3),\n",
    "        KNeighborsClassifier(5),\n",
    "        KNeighborsClassifier(7),\n",
    "        GaussianNB(),\n",
    "        GaussianNB(var_smoothing=0.1),\n",
    "        GaussianNB(var_smoothing=0.01),\n",
    "        RandomForestClassifier(max_depth=5, n_estimators=300),\n",
    "        RandomForestClassifier(max_depth=10, n_estimators=500),\n",
    "        RandomForestClassifier(max_depth=20, n_estimators=1000),\n",
    "        AdaBoostClassifier(learning_rate=0.1),\n",
    "        AdaBoostClassifier(learning_rate=0.01, n_estimators=100),\n",
    "        AdaBoostClassifier(learning_rate=0.1, n_estimators=500),\n",
    "        MLPClassifier(hidden_layer_sizes=(10, 5), learning_rate_init=0.01),\n",
    "        MLPClassifier(hidden_layer_sizes=(20, 10), learning_rate_init=0.001),\n",
    "        MLPClassifier(hidden_layer_sizes=(50, 25), learning_rate_init=0.0001),\n",
    "        LogisticRegression(),\n",
    "        LogisticRegression(C=0.1),\n",
    "        LogisticRegression(C=0.01) \n",
    "        \n",
    "    ]\n",
    "    \n",
    "    #Save the combination of scalers and classifiers\n",
    "    combinations = list(itertools.product(scaling, classifier))\n",
    "\n",
    "    # Initialize empty lists to store sums of profit and classification reports\n",
    "    profit_sums = []\n",
    "    classification_reports = []\n",
    "    results = []\n",
    "\n",
    "    #Put the pipeline in  for loop to see all the profits made by all combination\n",
    "    for i, combo in enumerate(combinations):\n",
    "        # Create a pipeline\n",
    "        pipe = Pipeline([\n",
    "            ('scaling', combo[0]),\n",
    "            ('classifier', combo[1])\n",
    "        ])\n",
    "\n",
    "        # Fit the model\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions on test set\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        \n",
    "        # Calculate classification report\n",
    "        clas_report = classification_report(y_test, y_pred)\n",
    "        classification_reports.append(clas_report)\n",
    "        \n",
    "        df_result = df.loc[y_test.index].copy()\n",
    "        df_result['y_prediction'] = y_pred\n",
    "\n",
    "        df_result_step2 = df_result.copy()\n",
    "        \n",
    "        df_result_step2['True_False'] = 0  # Initialize with 0 (incorrect prediction)\n",
    "    \n",
    "        # LOST BET\n",
    "        df_result_step2.loc[((df_result_step2['scor_diff'] < 0) & (df_result_step2['y_prediction'] > 0)) |\n",
    "                            ((df_result_step2['scor_diff'] > 0) & (df_result_step2['y_prediction'] < 0)), 'True_False'] = 0\n",
    "\n",
    "        # WON BET\n",
    "        df_result_step2.loc[((df_result_step2['scor_diff'] < 0) & (df_result_step2['y_prediction'] < 0)) |\n",
    "                            ((df_result_step2['scor_diff'] > 0) & (df_result_step2['y_prediction'] > 0)), 'True_False'] = 1\n",
    "\n",
    "        # NO BET\n",
    "        df_result_step2.loc[((df_result_step2['scor_diff'] == 0) & (df_result_step2['y_prediction'] == 0)) |\n",
    "                            ((df_result_step2['scor_diff'] == 0) & (df_result_step2['y_prediction'] != 0)) |\n",
    "                            ((df_result_step2['scor_diff'] != 0) & (df_result_step2['y_prediction'] == 0)), 'True_False'] = 2\n",
    "        df_result_step2['True_False'] = df_result_step2['True_False'].astype(int)\n",
    "\n",
    "        ########################################\n",
    "        df_result_step2 = probability_to_reg_dnb_odds(df_result_step2)\n",
    "        df_result_step2['profit'] = df_result_step2.apply(calculate_value_dnb, axis=1)\n",
    "\n",
    "        \n",
    "        # Calculate the sum of 'profit' column\n",
    "        profit_sum = df_result_step2['profit'].sum()\n",
    "        investment_total = (df_result_step2.True_False.value_counts().get(0, 0) + df_result_step2.True_False.value_counts().get(1, 0)) * 100\n",
    "        profit_ratio = profit_sum / investment_total\n",
    "        \n",
    "        results.append({\n",
    "            'combination': i + 1,\n",
    "            'scaler': combo[0].__class__.__name__,\n",
    "            'classifier': combo[1].__class__.__name__,\n",
    "            'profit_sum': profit_sum,\n",
    "            'profit_ratio': profit_ratio,\n",
    "            'investment_total': investment_total\n",
    "        })\n",
    "        \n",
    "        print(f\"Combination {i+1}: {combo} - Profit Sum: {profit_sum} - Profit ratio:\\\n",
    "        {profit_sum/((df_result_step2.True_False.value_counts().get(0, 0) + df_result_step2.True_False.value_counts().get(1, 0))*100)}\")\n",
    "        print(f\"Classification Report for Combination {i+1}:\\n{clas_report}\\n\")\n",
    "        print(df_result_step2.True_False.value_counts()) \n",
    "        \n",
    "    return results, classification_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d0fa7178",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 1: (MinMaxScaler(), KNeighborsClassifier(n_neighbors=3)) - Profit Sum: -1215.4610032597707 - Profit ratio:        -0.014333266547874654\n",
      "Classification Report for Combination 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.02      0.05      0.03        19\n",
      "          -3       0.10      0.19      0.13        68\n",
      "          -2       0.06      0.14      0.09       116\n",
      "          -1       0.19      0.28      0.23       274\n",
      "           0       0.28      0.32      0.30       401\n",
      "           1       0.25      0.11      0.16       348\n",
      "           2       0.21      0.09      0.13       174\n",
      "           3       0.11      0.03      0.05        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.19      1580\n",
      "   macro avg       0.08      0.08      0.07      1580\n",
      "weighted avg       0.20      0.19      0.18      1580\n",
      "\n",
      "\n",
      "2    732\n",
      "1    472\n",
      "0    376\n",
      "Name: True_False, dtype: int64\n",
      "Combination 2: (MinMaxScaler(), KNeighborsClassifier()) - Profit Sum: -3528.3250786433846 - Profit ratio:        -0.044605879628867064\n",
      "Classification Report for Combination 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.05      0.04      0.05        68\n",
      "          -2       0.08      0.09      0.09       116\n",
      "          -1       0.20      0.29      0.24       274\n",
      "           0       0.28      0.38      0.32       401\n",
      "           1       0.26      0.19      0.22       348\n",
      "           2       0.16      0.11      0.13       174\n",
      "           3       0.08      0.03      0.05        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.21      1580\n",
      "   macro avg       0.07      0.08      0.07      1580\n",
      "weighted avg       0.19      0.21      0.20      1580\n",
      "\n",
      "\n",
      "2    789\n",
      "1    460\n",
      "0    331\n",
      "Name: True_False, dtype: int64\n",
      "Combination 3: (MinMaxScaler(), KNeighborsClassifier(n_neighbors=7)) - Profit Sum: -213.73970309154947 - Profit ratio:        -0.002842283285791881\n",
      "Classification Report for Combination 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.02      0.01      0.02        68\n",
      "          -2       0.12      0.12      0.12       116\n",
      "          -1       0.20      0.28      0.23       274\n",
      "           0       0.28      0.41      0.33       401\n",
      "           1       0.23      0.18      0.20       348\n",
      "           2       0.18      0.13      0.15       174\n",
      "           3       0.12      0.03      0.05        87\n",
      "           4       0.17      0.01      0.03        68\n",
      "           5       0.25      0.10      0.14        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.22      1580\n",
      "   macro avg       0.10      0.09      0.09      1580\n",
      "weighted avg       0.20      0.22      0.20      1580\n",
      "\n",
      "\n",
      "2    828\n",
      "1    469\n",
      "0    283\n",
      "Name: True_False, dtype: int64\n",
      "Combination 4: (MinMaxScaler(), GaussianNB()) - Profit Sum: 3325.0590676731263 - Profit ratio:        0.0528626242873311\n",
      "Classification Report for Combination 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.03      0.14      0.05         7\n",
      "          -4       0.04      0.16      0.06        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.10      0.09      0.10       116\n",
      "          -1       0.22      0.18      0.20       274\n",
      "           0       0.28      0.54      0.37       401\n",
      "           1       0.27      0.05      0.08       348\n",
      "           2       0.24      0.13      0.17       174\n",
      "           3       0.16      0.11      0.14        87\n",
      "           4       0.11      0.03      0.05        68\n",
      "           5       0.04      0.20      0.06        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.21      1580\n",
      "   macro avg       0.09      0.10      0.08      1580\n",
      "weighted avg       0.22      0.21      0.18      1580\n",
      "\n",
      "\n",
      "2    951\n",
      "1    482\n",
      "0    147\n",
      "Name: True_False, dtype: int64\n",
      "Combination 5: (MinMaxScaler(), GaussianNB(var_smoothing=0.1)) - Profit Sum: 2946.8743473509358 - Profit ratio:        0.05407108894221901\n",
      "Classification Report for Combination 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.04      0.11      0.05        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.14      0.09      0.11       116\n",
      "          -1       0.21      0.15      0.18       274\n",
      "           0       0.27      0.60      0.38       401\n",
      "           1       0.19      0.03      0.05       348\n",
      "           2       0.23      0.14      0.17       174\n",
      "           3       0.17      0.05      0.07        87\n",
      "           4       0.14      0.01      0.03        68\n",
      "           5       0.05      0.20      0.08        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.21      1580\n",
      "   macro avg       0.09      0.09      0.07      1580\n",
      "weighted avg       0.20      0.21      0.17      1580\n",
      "\n",
      "\n",
      "2    1035\n",
      "1     424\n",
      "0     121\n",
      "Name: True_False, dtype: int64\n",
      "Combination 6: (MinMaxScaler(), GaussianNB(var_smoothing=0.01)) - Profit Sum: 3244.5474696777846 - Profit ratio:        0.05191275951484455\n",
      "Classification Report for Combination 6:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.03      0.14      0.05         7\n",
      "          -4       0.04      0.16      0.06        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.10      0.09      0.09       116\n",
      "          -1       0.23      0.18      0.20       274\n",
      "           0       0.28      0.54      0.37       401\n",
      "           1       0.25      0.04      0.07       348\n",
      "           2       0.23      0.13      0.16       174\n",
      "           3       0.17      0.10      0.13        87\n",
      "           4       0.13      0.03      0.05        68\n",
      "           5       0.04      0.20      0.07        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.21      1580\n",
      "   macro avg       0.09      0.10      0.08      1580\n",
      "weighted avg       0.21      0.21      0.18      1580\n",
      "\n",
      "\n",
      "2    955\n",
      "1    479\n",
      "0    146\n",
      "Name: True_False, dtype: int64\n",
      "Combination 7: (MinMaxScaler(), RandomForestClassifier(max_depth=5, n_estimators=300)) - Profit Sum: 254.38456096367804 - Profit ratio:        0.007827217260420863\n",
      "Classification Report for Combination 7:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.07      0.01      0.02       116\n",
      "          -1       0.24      0.18      0.21       274\n",
      "           0       0.27      0.78      0.40       401\n",
      "           1       0.30      0.08      0.13       348\n",
      "           2       0.16      0.08      0.11       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      1580\n",
      "   macro avg       0.07      0.08      0.06      1580\n",
      "weighted avg       0.20      0.26      0.18      1580\n",
      "\n",
      "\n",
      "2    1255\n",
      "1     266\n",
      "0      59\n",
      "Name: True_False, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 8: (MinMaxScaler(), RandomForestClassifier(max_depth=10, n_estimators=500)) - Profit Sum: 3175.945452738582 - Profit ratio:        0.09259316188742221\n",
      "Classification Report for Combination 8:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.09      0.03      0.04       116\n",
      "          -1       0.26      0.18      0.22       274\n",
      "           0       0.26      0.74      0.39       401\n",
      "           1       0.30      0.11      0.16       348\n",
      "           2       0.20      0.09      0.12       174\n",
      "           3       0.20      0.02      0.04        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      1580\n",
      "   macro avg       0.09      0.08      0.06      1580\n",
      "weighted avg       0.22      0.26      0.19      1580\n",
      "\n",
      "\n",
      "2    1237\n",
      "1     283\n",
      "0      60\n",
      "Name: True_False, dtype: int64\n",
      "Combination 9: (MinMaxScaler(), RandomForestClassifier(max_depth=20, n_estimators=1000)) - Profit Sum: 3242.9696628363995 - Profit ratio:        0.06645429636959835\n",
      "Classification Report for Combination 9:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.20      0.01      0.03        68\n",
      "          -2       0.08      0.03      0.05       116\n",
      "          -1       0.25      0.22      0.23       274\n",
      "           0       0.26      0.60      0.36       401\n",
      "           1       0.27      0.16      0.20       348\n",
      "           2       0.16      0.10      0.12       174\n",
      "           3       0.09      0.02      0.04        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.24      1580\n",
      "   macro avg       0.09      0.08      0.07      1580\n",
      "weighted avg       0.20      0.24      0.20      1580\n",
      "\n",
      "\n",
      "2    1092\n",
      "1     362\n",
      "0     126\n",
      "Name: True_False, dtype: int64\n",
      "Combination 10: (MinMaxScaler(), AdaBoostClassifier(learning_rate=0.1)) - Profit Sum: 264.1982387280452 - Profit ratio:        0.012403673179720433\n",
      "Classification Report for Combination 10:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.31      0.07      0.11       274\n",
      "           0       0.27      0.87      0.41       401\n",
      "           1       0.30      0.16      0.21       348\n",
      "           2       0.06      0.01      0.01       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.27      1580\n",
      "   macro avg       0.06      0.07      0.05      1580\n",
      "weighted avg       0.19      0.27      0.17      1580\n",
      "\n",
      "\n",
      "2    1367\n",
      "1     183\n",
      "0      30\n",
      "Name: True_False, dtype: int64\n",
      "Combination 11: (MinMaxScaler(), AdaBoostClassifier(learning_rate=0.01, n_estimators=100)) - Profit Sum: 0 - Profit ratio:        nan\n",
      "Classification Report for Combination 11:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.00      0.00      0.00       274\n",
      "           0       0.25      1.00      0.40       401\n",
      "           1       0.00      0.00      0.00       348\n",
      "           2       0.00      0.00      0.00       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.02      0.07      0.03      1580\n",
      "weighted avg       0.06      0.25      0.10      1580\n",
      "\n",
      "\n",
      "2    1580\n",
      "Name: True_False, dtype: int64\n",
      "Combination 12: (MinMaxScaler(), AdaBoostClassifier(learning_rate=0.1, n_estimators=500)) - Profit Sum: 518.0720767425748 - Profit ratio:        0.012132835520903391\n",
      "Classification Report for Combination 12:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.23      0.18      0.20       274\n",
      "           0       0.27      0.69      0.39       401\n",
      "           1       0.23      0.04      0.06       348\n",
      "           2       0.16      0.14      0.15       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.12      0.01      0.03        68\n",
      "           5       0.07      0.30      0.11        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.23      1580\n",
      "   macro avg       0.07      0.08      0.06      1580\n",
      "weighted avg       0.18      0.23      0.17      1580\n",
      "\n",
      "\n",
      "2    1153\n",
      "1     341\n",
      "0      86\n",
      "Name: True_False, dtype: int64\n",
      "Combination 13: (MinMaxScaler(), MLPClassifier(hidden_layer_sizes=(10, 5), learning_rate_init=0.01)) - Profit Sum: 1312.1696326452 - Profit ratio:        0.032722434729306735\n",
      "Classification Report for Combination 13:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.27      0.16      0.20       274\n",
      "           0       0.28      0.75      0.40       401\n",
      "           1       0.25      0.11      0.15       348\n",
      "           2       0.16      0.16      0.16       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      1580\n",
      "   macro avg       0.06      0.08      0.06      1580\n",
      "weighted avg       0.19      0.26      0.19      1580\n",
      "\n",
      "\n",
      "2    1179\n",
      "1     336\n",
      "0      65\n",
      "Name: True_False, dtype: int64\n",
      "Combination 14: (MinMaxScaler(), MLPClassifier(hidden_layer_sizes=(20, 10))) - Profit Sum: 114.95163464598318 - Profit ratio:        0.002554480769910737\n",
      "Classification Report for Combination 14:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.23      0.28      0.25       274\n",
      "           0       0.27      0.66      0.38       401\n",
      "           1       0.26      0.09      0.13       348\n",
      "           2       0.17      0.13      0.15       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.06      0.08      0.06      1580\n",
      "weighted avg       0.18      0.25      0.19      1580\n",
      "\n",
      "\n",
      "2    1130\n",
      "1     344\n",
      "0     106\n",
      "Name: True_False, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 15: (MinMaxScaler(), MLPClassifier(hidden_layer_sizes=(50, 25), learning_rate_init=0.0001)) - Profit Sum: 481.67779137990374 - Profit ratio:        0.022508308008406717\n",
      "Classification Report for Combination 15:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.30      0.14      0.19       274\n",
      "           0       0.27      0.89      0.41       401\n",
      "           1       0.31      0.04      0.07       348\n",
      "           2       0.19      0.09      0.12       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.27      1580\n",
      "   macro avg       0.07      0.08      0.05      1580\n",
      "weighted avg       0.21      0.27      0.17      1580\n",
      "\n",
      "\n",
      "2    1366\n",
      "1     183\n",
      "0      31\n",
      "Name: True_False, dtype: int64\n",
      "Combination 16: (MinMaxScaler(), LogisticRegression()) - Profit Sum: -52.64423362139314 - Profit ratio:        -0.0018602202693071782\n",
      "Classification Report for Combination 16:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.07      0.03      0.05       116\n",
      "          -1       0.20      0.09      0.13       274\n",
      "           0       0.27      0.83      0.41       401\n",
      "           1       0.29      0.08      0.13       348\n",
      "           2       0.17      0.07      0.10       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.07      0.07      0.05      1580\n",
      "weighted avg       0.19      0.25      0.17      1580\n",
      "\n",
      "\n",
      "2    1297\n",
      "1     230\n",
      "0      53\n",
      "Name: True_False, dtype: int64\n",
      "Combination 17: (MinMaxScaler(), LogisticRegression(C=0.1)) - Profit Sum: 16.611288991450493 - Profit ratio:        0.0007285653066425655\n",
      "Classification Report for Combination 17:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.07      0.02      0.03       116\n",
      "          -1       0.24      0.09      0.13       274\n",
      "           0       0.27      0.87      0.41       401\n",
      "           1       0.27      0.06      0.10       348\n",
      "           2       0.20      0.07      0.11       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      1580\n",
      "   macro avg       0.07      0.07      0.05      1580\n",
      "weighted avg       0.20      0.26      0.16      1580\n",
      "\n",
      "\n",
      "2    1352\n",
      "1     191\n",
      "0      37\n",
      "Name: True_False, dtype: int64\n",
      "Combination 18: (MinMaxScaler(), LogisticRegression(C=0.01)) - Profit Sum: -101.44740500794933 - Profit ratio:        -0.010247212627065589\n",
      "Classification Report for Combination 18:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.27      0.05      0.08       274\n",
      "           0       0.26      0.94      0.40       401\n",
      "           1       0.27      0.04      0.07       348\n",
      "           2       0.21      0.02      0.04       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      1580\n",
      "   macro avg       0.07      0.07      0.04      1580\n",
      "weighted avg       0.19      0.26      0.14      1580\n",
      "\n",
      "\n",
      "2    1481\n",
      "1      87\n",
      "0      12\n",
      "Name: True_False, dtype: int64\n",
      "Combination 19: (StandardScaler(), KNeighborsClassifier(n_neighbors=3)) - Profit Sum: 1568.8411309290796 - Profit ratio:        0.01867668013010809\n",
      "Classification Report for Combination 19:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.05      0.11      0.06        19\n",
      "          -3       0.09      0.19      0.12        68\n",
      "          -2       0.08      0.18      0.11       116\n",
      "          -1       0.19      0.27      0.22       274\n",
      "           0       0.26      0.30      0.28       401\n",
      "           1       0.25      0.13      0.17       348\n",
      "           2       0.18      0.06      0.09       174\n",
      "           3       0.14      0.03      0.06        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.18      1580\n",
      "   macro avg       0.08      0.09      0.07      1580\n",
      "weighted avg       0.19      0.18      0.18      1580\n",
      "\n",
      "\n",
      "2    740\n",
      "1    474\n",
      "0    366\n",
      "Name: True_False, dtype: int64\n",
      "Combination 20: (StandardScaler(), KNeighborsClassifier()) - Profit Sum: -234.88668127528405 - Profit ratio:        -0.0029960035876949497\n",
      "Classification Report for Combination 20:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.11      0.13      0.12        68\n",
      "          -2       0.09      0.12      0.10       116\n",
      "          -1       0.19      0.26      0.22       274\n",
      "           0       0.27      0.36      0.31       401\n",
      "           1       0.22      0.16      0.18       348\n",
      "           2       0.17      0.10      0.13       174\n",
      "           3       0.12      0.06      0.08        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.20      1580\n",
      "   macro avg       0.08      0.08      0.08      1580\n",
      "weighted avg       0.19      0.20      0.19      1580\n",
      "\n",
      "\n",
      "2    796\n",
      "1    470\n",
      "0    314\n",
      "Name: True_False, dtype: int64\n",
      "Combination 21: (StandardScaler(), KNeighborsClassifier(n_neighbors=7)) - Profit Sum: -824.0434600738017 - Profit ratio:        -0.011105707009080886\n",
      "Classification Report for Combination 21:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.09      0.06      0.07        68\n",
      "          -2       0.08      0.09      0.09       116\n",
      "          -1       0.22      0.31      0.26       274\n",
      "           0       0.28      0.42      0.33       401\n",
      "           1       0.24      0.18      0.20       348\n",
      "           2       0.16      0.10      0.12       174\n",
      "           3       0.12      0.03      0.05        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.22      1580\n",
      "   macro avg       0.08      0.08      0.08      1580\n",
      "weighted avg       0.20      0.22      0.20      1580\n",
      "\n",
      "\n",
      "2    838\n",
      "1    458\n",
      "0    284\n",
      "Name: True_False, dtype: int64\n",
      "Combination 22: (StandardScaler(), GaussianNB()) - Profit Sum: 3325.0590676731263 - Profit ratio:        0.0528626242873311\n",
      "Classification Report for Combination 22:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.03      0.14      0.05         7\n",
      "          -4       0.04      0.16      0.06        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.10      0.09      0.10       116\n",
      "          -1       0.22      0.18      0.20       274\n",
      "           0       0.28      0.54      0.37       401\n",
      "           1       0.27      0.05      0.08       348\n",
      "           2       0.24      0.13      0.17       174\n",
      "           3       0.16      0.11      0.14        87\n",
      "           4       0.11      0.03      0.05        68\n",
      "           5       0.04      0.20      0.06        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.21      1580\n",
      "   macro avg       0.09      0.10      0.08      1580\n",
      "weighted avg       0.22      0.21      0.18      1580\n",
      "\n",
      "\n",
      "2    951\n",
      "1    482\n",
      "0    147\n",
      "Name: True_False, dtype: int64\n",
      "Combination 23: (StandardScaler(), GaussianNB(var_smoothing=0.1)) - Profit Sum: 3199.267784725779 - Profit ratio:        0.05244701286435704\n",
      "Classification Report for Combination 23:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.04      0.14      0.06         7\n",
      "          -4       0.04      0.16      0.06        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.12      0.09      0.10       116\n",
      "          -1       0.24      0.19      0.21       274\n",
      "           0       0.28      0.55      0.37       401\n",
      "           1       0.22      0.04      0.06       348\n",
      "           2       0.23      0.13      0.16       174\n",
      "           3       0.16      0.09      0.12        87\n",
      "           4       0.10      0.01      0.03        68\n",
      "           5       0.04      0.20      0.07        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.21      1580\n",
      "   macro avg       0.09      0.10      0.08      1580\n",
      "weighted avg       0.21      0.21      0.18      1580\n",
      "\n",
      "\n",
      "2    970\n",
      "1    468\n",
      "0    142\n",
      "Name: True_False, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 24: (StandardScaler(), GaussianNB(var_smoothing=0.01)) - Profit Sum: 3424.9432153415564 - Profit ratio:        0.05445060755709947\n",
      "Classification Report for Combination 24:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.03      0.14      0.05         7\n",
      "          -4       0.04      0.16      0.06        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.10      0.09      0.09       116\n",
      "          -1       0.22      0.18      0.20       274\n",
      "           0       0.28      0.54      0.37       401\n",
      "           1       0.27      0.05      0.08       348\n",
      "           2       0.24      0.13      0.17       174\n",
      "           3       0.17      0.11      0.14        87\n",
      "           4       0.12      0.03      0.05        68\n",
      "           5       0.04      0.20      0.06        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.21      1580\n",
      "   macro avg       0.09      0.10      0.08      1580\n",
      "weighted avg       0.22      0.21      0.18      1580\n",
      "\n",
      "\n",
      "2    951\n",
      "1    483\n",
      "0    146\n",
      "Name: True_False, dtype: int64\n",
      "Combination 25: (StandardScaler(), RandomForestClassifier(max_depth=5, n_estimators=300)) - Profit Sum: 361.17248433368445 - Profit ratio:        0.011576041164541168\n",
      "Classification Report for Combination 25:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.25      0.18      0.21       274\n",
      "           0       0.27      0.79      0.40       401\n",
      "           1       0.34      0.10      0.16       348\n",
      "           2       0.15      0.07      0.09       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      1580\n",
      "   macro avg       0.07      0.08      0.06      1580\n",
      "weighted avg       0.20      0.26      0.18      1580\n",
      "\n",
      "\n",
      "2    1268\n",
      "1     257\n",
      "0      55\n",
      "Name: True_False, dtype: int64\n",
      "Combination 26: (StandardScaler(), RandomForestClassifier(max_depth=10, n_estimators=500)) - Profit Sum: 2043.6224159292165 - Profit ratio:        0.05993027612695649\n",
      "Classification Report for Combination 26:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.09      0.03      0.04       116\n",
      "          -1       0.25      0.18      0.21       274\n",
      "           0       0.26      0.74      0.39       401\n",
      "           1       0.25      0.09      0.13       348\n",
      "           2       0.20      0.09      0.13       174\n",
      "           3       0.18      0.02      0.04        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.08      0.08      0.06      1580\n",
      "weighted avg       0.20      0.25      0.18      1580\n",
      "\n",
      "\n",
      "2    1239\n",
      "1     279\n",
      "0      62\n",
      "Name: True_False, dtype: int64\n",
      "Combination 27: (StandardScaler(), RandomForestClassifier(max_depth=20, n_estimators=1000)) - Profit Sum: 2790.201083448345 - Profit ratio:        0.05659637086102119\n",
      "Classification Report for Combination 27:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.33      0.05      0.09        19\n",
      "          -3       0.17      0.01      0.03        68\n",
      "          -2       0.09      0.04      0.06       116\n",
      "          -1       0.25      0.22      0.23       274\n",
      "           0       0.26      0.59      0.36       401\n",
      "           1       0.28      0.18      0.22       348\n",
      "           2       0.17      0.10      0.13       174\n",
      "           3       0.15      0.03      0.06        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.11      0.08      0.08      1580\n",
      "weighted avg       0.22      0.25      0.20      1580\n",
      "\n",
      "\n",
      "2    1087\n",
      "1     361\n",
      "0     132\n",
      "Name: True_False, dtype: int64\n",
      "Combination 28: (StandardScaler(), AdaBoostClassifier(learning_rate=0.1)) - Profit Sum: 264.1982387280452 - Profit ratio:        0.012403673179720433\n",
      "Classification Report for Combination 28:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.31      0.07      0.11       274\n",
      "           0       0.27      0.87      0.41       401\n",
      "           1       0.30      0.16      0.21       348\n",
      "           2       0.06      0.01      0.01       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.27      1580\n",
      "   macro avg       0.06      0.07      0.05      1580\n",
      "weighted avg       0.19      0.27      0.17      1580\n",
      "\n",
      "\n",
      "2    1367\n",
      "1     183\n",
      "0      30\n",
      "Name: True_False, dtype: int64\n",
      "Combination 29: (StandardScaler(), AdaBoostClassifier(learning_rate=0.01, n_estimators=100)) - Profit Sum: 0 - Profit ratio:        nan\n",
      "Classification Report for Combination 29:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.00      0.00      0.00       274\n",
      "           0       0.25      1.00      0.40       401\n",
      "           1       0.00      0.00      0.00       348\n",
      "           2       0.00      0.00      0.00       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.02      0.07      0.03      1580\n",
      "weighted avg       0.06      0.25      0.10      1580\n",
      "\n",
      "\n",
      "2    1580\n",
      "Name: True_False, dtype: int64\n",
      "Combination 30: (StandardScaler(), AdaBoostClassifier(learning_rate=0.1, n_estimators=500)) - Profit Sum: 518.0720767425748 - Profit ratio:        0.012132835520903391\n",
      "Classification Report for Combination 30:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.23      0.18      0.20       274\n",
      "           0       0.27      0.69      0.39       401\n",
      "           1       0.23      0.04      0.06       348\n",
      "           2       0.16      0.14      0.15       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.12      0.01      0.03        68\n",
      "           5       0.07      0.30      0.11        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.23      1580\n",
      "   macro avg       0.07      0.08      0.06      1580\n",
      "weighted avg       0.18      0.23      0.17      1580\n",
      "\n",
      "\n",
      "2    1153\n",
      "1     341\n",
      "0      86\n",
      "Name: True_False, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 31: (StandardScaler(), MLPClassifier(hidden_layer_sizes=(10, 5), learning_rate_init=0.01)) - Profit Sum: 550.9122614618768 - Profit ratio:        0.018363742048729228\n",
      "Classification Report for Combination 31:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.19      0.04      0.07       116\n",
      "          -1       0.31      0.12      0.17       274\n",
      "           0       0.27      0.82      0.41       401\n",
      "           1       0.26      0.13      0.17       348\n",
      "           2       0.17      0.07      0.10       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.27      1580\n",
      "   macro avg       0.08      0.08      0.06      1580\n",
      "weighted avg       0.21      0.27      0.19      1580\n",
      "\n",
      "\n",
      "2    1280\n",
      "1     248\n",
      "0      52\n",
      "Name: True_False, dtype: int64\n",
      "Combination 32: (StandardScaler(), MLPClassifier(hidden_layer_sizes=(20, 10))) - Profit Sum: -93.78897322792716 - Profit ratio:        -0.0024424211778106032\n",
      "Classification Report for Combination 32:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.10      0.06      0.08       116\n",
      "          -1       0.22      0.17      0.19       274\n",
      "           0       0.25      0.66      0.36       401\n",
      "           1       0.27      0.11      0.16       348\n",
      "           2       0.17      0.09      0.12       174\n",
      "           3       0.12      0.01      0.02        87\n",
      "           4       0.17      0.01      0.03        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.24      1580\n",
      "   macro avg       0.09      0.07      0.06      1580\n",
      "weighted avg       0.20      0.24      0.18      1580\n",
      "\n",
      "\n",
      "2    1196\n",
      "1     276\n",
      "0     108\n",
      "Name: True_False, dtype: int64\n",
      "Combination 33: (StandardScaler(), MLPClassifier(hidden_layer_sizes=(50, 25), learning_rate_init=0.0001)) - Profit Sum: 1456.4061910417179 - Profit ratio:        0.04125796575189002\n",
      "Classification Report for Combination 33:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.08      0.05      0.06       116\n",
      "          -1       0.25      0.11      0.15       274\n",
      "           0       0.27      0.77      0.40       401\n",
      "           1       0.28      0.11      0.16       348\n",
      "           2       0.17      0.11      0.13       174\n",
      "           3       0.11      0.01      0.02        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.08      0.08      0.06      1580\n",
      "weighted avg       0.21      0.25      0.18      1580\n",
      "\n",
      "\n",
      "2    1227\n",
      "1     283\n",
      "0      70\n",
      "Name: True_False, dtype: int64\n",
      "Combination 34: (StandardScaler(), LogisticRegression()) - Profit Sum: 62.93343229246523 - Profit ratio:        0.0021118601440424573\n",
      "Classification Report for Combination 34:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.08      0.04      0.06       116\n",
      "          -1       0.20      0.09      0.12       274\n",
      "           0       0.27      0.82      0.41       401\n",
      "           1       0.28      0.08      0.12       348\n",
      "           2       0.17      0.08      0.11       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.07      0.07      0.05      1580\n",
      "weighted avg       0.19      0.25      0.17      1580\n",
      "\n",
      "\n",
      "2    1282\n",
      "1     241\n",
      "0      57\n",
      "Name: True_False, dtype: int64\n",
      "Combination 35: (StandardScaler(), LogisticRegression(C=0.1)) - Profit Sum: -99.74628353972639 - Profit ratio:        -0.0033698068763421078\n",
      "Classification Report for Combination 35:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.07      0.03      0.05       116\n",
      "          -1       0.20      0.09      0.13       274\n",
      "           0       0.27      0.83      0.41       401\n",
      "           1       0.28      0.08      0.12       348\n",
      "           2       0.17      0.08      0.11       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      1580\n",
      "   macro avg       0.07      0.07      0.05      1580\n",
      "weighted avg       0.19      0.26      0.17      1580\n",
      "\n",
      "\n",
      "2    1284\n",
      "1     239\n",
      "0      57\n",
      "Name: True_False, dtype: int64\n",
      "Combination 36: (StandardScaler(), LogisticRegression(C=0.01)) - Profit Sum: -212.36003865077942 - Profit ratio:        -0.008013586364180356\n",
      "Classification Report for Combination 36:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.08      0.03      0.04       116\n",
      "          -1       0.19      0.09      0.12       274\n",
      "           0       0.27      0.84      0.41       401\n",
      "           1       0.26      0.07      0.11       348\n",
      "           2       0.19      0.08      0.11       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.07      0.07      0.05      1580\n",
      "weighted avg       0.18      0.25      0.16      1580\n",
      "\n",
      "\n",
      "2    1315\n",
      "1     217\n",
      "0      48\n",
      "Name: True_False, dtype: int64\n",
      "Combination 37: (RobustScaler(), KNeighborsClassifier(n_neighbors=3)) - Profit Sum: 1032.5507506069707 - Profit ratio:        0.012306921938104539\n",
      "Classification Report for Combination 37:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.10      0.21      0.13        68\n",
      "          -2       0.08      0.18      0.11       116\n",
      "          -1       0.20      0.28      0.23       274\n",
      "           0       0.27      0.31      0.28       401\n",
      "           1       0.27      0.15      0.19       348\n",
      "           2       0.17      0.06      0.09       174\n",
      "           3       0.06      0.01      0.02        87\n",
      "           4       0.17      0.01      0.03        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.19      1580\n",
      "   macro avg       0.09      0.08      0.07      1580\n",
      "weighted avg       0.20      0.19      0.18      1580\n",
      "\n",
      "\n",
      "2    741\n",
      "1    474\n",
      "0    365\n",
      "Name: True_False, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 38: (RobustScaler(), KNeighborsClassifier()) - Profit Sum: 3442.4610556341113 - Profit ratio:        0.04476542335024852\n",
      "Classification Report for Combination 38:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.11      0.11      0.11        19\n",
      "          -3       0.04      0.04      0.04        68\n",
      "          -2       0.11      0.14      0.12       116\n",
      "          -1       0.21      0.28      0.24       274\n",
      "           0       0.28      0.39      0.32       401\n",
      "           1       0.25      0.17      0.20       348\n",
      "           2       0.21      0.13      0.16       174\n",
      "           3       0.06      0.02      0.03        87\n",
      "           4       0.08      0.01      0.03        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.22      1580\n",
      "   macro avg       0.09      0.09      0.08      1580\n",
      "weighted avg       0.20      0.22      0.20      1580\n",
      "\n",
      "\n",
      "2    811\n",
      "1    478\n",
      "0    291\n",
      "Name: True_False, dtype: int64\n",
      "Combination 39: (RobustScaler(), KNeighborsClassifier(n_neighbors=7)) - Profit Sum: -1556.9000579386723 - Profit ratio:        -0.021897328522344196\n",
      "Classification Report for Combination 39:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.02      0.01      0.02        68\n",
      "          -2       0.10      0.13      0.11       116\n",
      "          -1       0.22      0.29      0.25       274\n",
      "           0       0.28      0.46      0.35       401\n",
      "           1       0.26      0.18      0.22       348\n",
      "           2       0.17      0.10      0.13       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.23      1580\n",
      "   macro avg       0.07      0.08      0.07      1580\n",
      "weighted avg       0.20      0.23      0.20      1580\n",
      "\n",
      "\n",
      "2    869\n",
      "1    434\n",
      "0    277\n",
      "Name: True_False, dtype: int64\n",
      "Combination 40: (RobustScaler(), GaussianNB()) - Profit Sum: 3325.0590676731263 - Profit ratio:        0.0528626242873311\n",
      "Classification Report for Combination 40:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.03      0.14      0.05         7\n",
      "          -4       0.04      0.16      0.06        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.10      0.09      0.10       116\n",
      "          -1       0.22      0.18      0.20       274\n",
      "           0       0.28      0.54      0.37       401\n",
      "           1       0.27      0.05      0.08       348\n",
      "           2       0.24      0.13      0.17       174\n",
      "           3       0.16      0.11      0.14        87\n",
      "           4       0.11      0.03      0.05        68\n",
      "           5       0.04      0.20      0.06        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.21      1580\n",
      "   macro avg       0.09      0.10      0.08      1580\n",
      "weighted avg       0.22      0.21      0.18      1580\n",
      "\n",
      "\n",
      "2    951\n",
      "1    482\n",
      "0    147\n",
      "Name: True_False, dtype: int64\n",
      "Combination 41: (RobustScaler(), GaussianNB(var_smoothing=0.1)) - Profit Sum: -26.409790558643103 - Profit ratio:        -0.018864136113316502\n",
      "Classification Report for Combination 41:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.00      0.00      0.00       274\n",
      "           0       0.26      1.00      0.41       401\n",
      "           1       0.00      0.00      0.00       348\n",
      "           2       0.29      0.02      0.04       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      1580\n",
      "   macro avg       0.04      0.07      0.03      1580\n",
      "weighted avg       0.10      0.26      0.11      1580\n",
      "\n",
      "\n",
      "2    1566\n",
      "1      13\n",
      "0       1\n",
      "Name: True_False, dtype: int64\n",
      "Combination 42: (RobustScaler(), GaussianNB(var_smoothing=0.01)) - Profit Sum: 2276.2511543022333 - Profit ratio:        0.05690627885755583\n",
      "Classification Report for Combination 42:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -8       0.00      0.00      0.00         0\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.15      0.06      0.09       116\n",
      "          -1       0.28      0.15      0.19       274\n",
      "           0       0.27      0.74      0.40       401\n",
      "           1       0.23      0.03      0.05       348\n",
      "           2       0.17      0.11      0.13       174\n",
      "           3       0.14      0.01      0.02        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.07      0.10      0.08        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.24      1580\n",
      "   macro avg       0.08      0.07      0.06      1580\n",
      "weighted avg       0.21      0.24      0.17      1580\n",
      "\n",
      "\n",
      "2    1180\n",
      "1     320\n",
      "0      80\n",
      "Name: True_False, dtype: int64\n",
      "Combination 43: (RobustScaler(), RandomForestClassifier(max_depth=5, n_estimators=300)) - Profit Sum: 627.6813800705619 - Profit ratio:        0.019926393018113074\n",
      "Classification Report for Combination 43:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.05      0.01      0.01       116\n",
      "          -1       0.23      0.16      0.19       274\n",
      "           0       0.27      0.78      0.40       401\n",
      "           1       0.32      0.09      0.15       348\n",
      "           2       0.14      0.07      0.09       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      1580\n",
      "   macro avg       0.07      0.07      0.06      1580\n",
      "weighted avg       0.20      0.26      0.18      1580\n",
      "\n",
      "\n",
      "2    1265\n",
      "1     262\n",
      "0      53\n",
      "Name: True_False, dtype: int64\n",
      "Combination 44: (RobustScaler(), RandomForestClassifier(max_depth=10, n_estimators=500)) - Profit Sum: 2316.568521087297 - Profit ratio:        0.0658116057127073\n",
      "Classification Report for Combination 44:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.07      0.02      0.03       116\n",
      "          -1       0.25      0.18      0.21       274\n",
      "           0       0.26      0.73      0.38       401\n",
      "           1       0.27      0.10      0.15       348\n",
      "           2       0.20      0.10      0.13       174\n",
      "           3       0.11      0.01      0.02        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.08      0.08      0.06      1580\n",
      "weighted avg       0.20      0.25      0.18      1580\n",
      "\n",
      "\n",
      "2    1228\n",
      "1     289\n",
      "0      63\n",
      "Name: True_False, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 45: (RobustScaler(), RandomForestClassifier(max_depth=20, n_estimators=1000)) - Profit Sum: 2130.312145730942 - Profit ratio:        0.04193527845927052\n",
      "Classification Report for Combination 45:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.25      0.05      0.09        19\n",
      "          -3       0.14      0.01      0.03        68\n",
      "          -2       0.09      0.04      0.06       116\n",
      "          -1       0.25      0.22      0.23       274\n",
      "           0       0.26      0.60      0.37       401\n",
      "           1       0.27      0.17      0.21       348\n",
      "           2       0.19      0.11      0.14       174\n",
      "           3       0.08      0.02      0.04        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.10      0.08      0.08      1580\n",
      "weighted avg       0.21      0.25      0.20      1580\n",
      "\n",
      "\n",
      "2    1072\n",
      "1     368\n",
      "0     140\n",
      "Name: True_False, dtype: int64\n",
      "Combination 46: (RobustScaler(), AdaBoostClassifier(learning_rate=0.1)) - Profit Sum: 264.1982387280452 - Profit ratio:        0.012403673179720433\n",
      "Classification Report for Combination 46:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.31      0.07      0.11       274\n",
      "           0       0.27      0.87      0.41       401\n",
      "           1       0.30      0.16      0.21       348\n",
      "           2       0.06      0.01      0.01       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.27      1580\n",
      "   macro avg       0.06      0.07      0.05      1580\n",
      "weighted avg       0.19      0.27      0.17      1580\n",
      "\n",
      "\n",
      "2    1367\n",
      "1     183\n",
      "0      30\n",
      "Name: True_False, dtype: int64\n",
      "Combination 47: (RobustScaler(), AdaBoostClassifier(learning_rate=0.01, n_estimators=100)) - Profit Sum: 0 - Profit ratio:        nan\n",
      "Classification Report for Combination 47:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.00      0.00      0.00       274\n",
      "           0       0.25      1.00      0.40       401\n",
      "           1       0.00      0.00      0.00       348\n",
      "           2       0.00      0.00      0.00       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.02      0.07      0.03      1580\n",
      "weighted avg       0.06      0.25      0.10      1580\n",
      "\n",
      "\n",
      "2    1580\n",
      "Name: True_False, dtype: int64\n",
      "Combination 48: (RobustScaler(), AdaBoostClassifier(learning_rate=0.1, n_estimators=500)) - Profit Sum: 518.0720767425748 - Profit ratio:        0.012132835520903391\n",
      "Classification Report for Combination 48:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.23      0.18      0.20       274\n",
      "           0       0.27      0.69      0.39       401\n",
      "           1       0.23      0.04      0.06       348\n",
      "           2       0.16      0.14      0.15       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.12      0.01      0.03        68\n",
      "           5       0.07      0.30      0.11        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.23      1580\n",
      "   macro avg       0.07      0.08      0.06      1580\n",
      "weighted avg       0.18      0.23      0.17      1580\n",
      "\n",
      "\n",
      "2    1153\n",
      "1     341\n",
      "0      86\n",
      "Name: True_False, dtype: int64\n",
      "Combination 49: (RobustScaler(), MLPClassifier(hidden_layer_sizes=(10, 5), learning_rate_init=0.01)) - Profit Sum: -365.3167992529533 - Profit ratio:        -0.008698019029832221\n",
      "Classification Report for Combination 49:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.19      0.05      0.08       116\n",
      "          -1       0.21      0.20      0.21       274\n",
      "           0       0.26      0.67      0.38       401\n",
      "           1       0.25      0.13      0.17       348\n",
      "           2       0.13      0.06      0.09       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.24      1580\n",
      "   macro avg       0.07      0.07      0.06      1580\n",
      "weighted avg       0.19      0.24      0.18      1580\n",
      "\n",
      "\n",
      "2    1160\n",
      "1     311\n",
      "0     109\n",
      "Name: True_False, dtype: int64\n",
      "Combination 50: (RobustScaler(), MLPClassifier(hidden_layer_sizes=(20, 10))) - Profit Sum: 113.61965498045248 - Profit ratio:        0.0024123068997972926\n",
      "Classification Report for Combination 50:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.14      0.07      0.09       116\n",
      "          -1       0.22      0.13      0.16       274\n",
      "           0       0.27      0.64      0.38       401\n",
      "           1       0.22      0.13      0.16       348\n",
      "           2       0.15      0.16      0.15       174\n",
      "           3       0.15      0.02      0.04        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.24      1580\n",
      "   macro avg       0.08      0.08      0.07      1580\n",
      "weighted avg       0.19      0.24      0.19      1580\n",
      "\n",
      "\n",
      "2    1109\n",
      "1     355\n",
      "0     116\n",
      "Name: True_False, dtype: int64\n",
      "Combination 51: (RobustScaler(), MLPClassifier(hidden_layer_sizes=(50, 25), learning_rate_init=0.0001)) - Profit Sum: -663.6944227129868 - Profit ratio:        -0.016717743645163395\n",
      "Classification Report for Combination 51:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.11      0.02      0.03       116\n",
      "          -1       0.22      0.20      0.21       274\n",
      "           0       0.27      0.72      0.39       401\n",
      "           1       0.23      0.05      0.09       348\n",
      "           2       0.15      0.13      0.14       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.07      0.08      0.06      1580\n",
      "weighted avg       0.18      0.25      0.17      1580\n",
      "\n",
      "\n",
      "2    1183\n",
      "1     298\n",
      "0      99\n",
      "Name: True_False, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 52: (RobustScaler(), LogisticRegression()) - Profit Sum: -530.2900498108388 - Profit ratio:        -0.016942174115362262\n",
      "Classification Report for Combination 52:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.10      0.07      0.08       116\n",
      "          -1       0.19      0.08      0.12       274\n",
      "           0       0.27      0.80      0.41       401\n",
      "           1       0.25      0.07      0.12       348\n",
      "           2       0.17      0.09      0.12       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.07      0.07      0.06      1580\n",
      "weighted avg       0.18      0.25      0.17      1580\n",
      "\n",
      "\n",
      "2    1267\n",
      "1     247\n",
      "0      66\n",
      "Name: True_False, dtype: int64\n",
      "Combination 53: (RobustScaler(), LogisticRegression(C=0.1)) - Profit Sum: 83.65121412524104 - Profit ratio:        0.0026984262621045497\n",
      "Classification Report for Combination 53:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.11      0.07      0.08       116\n",
      "          -1       0.20      0.09      0.12       274\n",
      "           0       0.27      0.82      0.41       401\n",
      "           1       0.31      0.08      0.13       348\n",
      "           2       0.18      0.10      0.13       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      1580\n",
      "   macro avg       0.07      0.08      0.06      1580\n",
      "weighted avg       0.20      0.26      0.17      1580\n",
      "\n",
      "\n",
      "2    1270\n",
      "1     250\n",
      "0      60\n",
      "Name: True_False, dtype: int64\n",
      "Combination 54: (RobustScaler(), LogisticRegression(C=0.01)) - Profit Sum: 373.701307284292 - Profit ratio:        0.014209175181912243\n",
      "Classification Report for Combination 54:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.07      0.03      0.04       116\n",
      "          -1       0.23      0.10      0.14       274\n",
      "           0       0.27      0.85      0.41       401\n",
      "           1       0.29      0.08      0.13       348\n",
      "           2       0.17      0.06      0.09       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      1580\n",
      "   macro avg       0.07      0.07      0.05      1580\n",
      "weighted avg       0.20      0.26      0.17      1580\n",
      "\n",
      "\n",
      "2    1317\n",
      "1     220\n",
      "0      43\n",
      "Name: True_False, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "results_a ,classification_reports_a = train_model_draw_no_bet(step10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ccbb6af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'combination': 1,\n",
       "  'scaler': 'MinMaxScaler',\n",
       "  'classifier': 'KNeighborsClassifier',\n",
       "  'profit_sum': -1215.4610032597707,\n",
       "  'profit_ratio': -0.014333266547874654,\n",
       "  'investment_total': 84800},\n",
       " {'combination': 2,\n",
       "  'scaler': 'MinMaxScaler',\n",
       "  'classifier': 'KNeighborsClassifier',\n",
       "  'profit_sum': -3528.3250786433846,\n",
       "  'profit_ratio': -0.044605879628867064,\n",
       "  'investment_total': 79100},\n",
       " {'combination': 3,\n",
       "  'scaler': 'MinMaxScaler',\n",
       "  'classifier': 'KNeighborsClassifier',\n",
       "  'profit_sum': -213.73970309154947,\n",
       "  'profit_ratio': -0.002842283285791881,\n",
       "  'investment_total': 75200},\n",
       " {'combination': 4,\n",
       "  'scaler': 'MinMaxScaler',\n",
       "  'classifier': 'GaussianNB',\n",
       "  'profit_sum': 3325.0590676731263,\n",
       "  'profit_ratio': 0.0528626242873311,\n",
       "  'investment_total': 62900},\n",
       " {'combination': 5,\n",
       "  'scaler': 'MinMaxScaler',\n",
       "  'classifier': 'GaussianNB',\n",
       "  'profit_sum': 2946.8743473509358,\n",
       "  'profit_ratio': 0.05407108894221901,\n",
       "  'investment_total': 54500},\n",
       " {'combination': 6,\n",
       "  'scaler': 'MinMaxScaler',\n",
       "  'classifier': 'GaussianNB',\n",
       "  'profit_sum': 3244.5474696777846,\n",
       "  'profit_ratio': 0.05191275951484455,\n",
       "  'investment_total': 62500},\n",
       " {'combination': 7,\n",
       "  'scaler': 'MinMaxScaler',\n",
       "  'classifier': 'RandomForestClassifier',\n",
       "  'profit_sum': 524.9907862097036,\n",
       "  'profit_ratio': 0.016772868569000118,\n",
       "  'investment_total': 31300},\n",
       " {'combination': 8,\n",
       "  'scaler': 'MinMaxScaler',\n",
       "  'classifier': 'RandomForestClassifier',\n",
       "  'profit_sum': 2133.1242967837675,\n",
       "  'profit_ratio': 0.06077277198814152,\n",
       "  'investment_total': 35100},\n",
       " {'combination': 9,\n",
       "  'scaler': 'MinMaxScaler',\n",
       "  'classifier': 'RandomForestClassifier',\n",
       "  'profit_sum': 2443.400760493895,\n",
       "  'profit_ratio': 0.04976376294284919,\n",
       "  'investment_total': 49100},\n",
       " {'combination': 10,\n",
       "  'scaler': 'MinMaxScaler',\n",
       "  'classifier': 'AdaBoostClassifier',\n",
       "  'profit_sum': 264.1982387280452,\n",
       "  'profit_ratio': 0.012403673179720433,\n",
       "  'investment_total': 21300},\n",
       " {'combination': 11,\n",
       "  'scaler': 'MinMaxScaler',\n",
       "  'classifier': 'AdaBoostClassifier',\n",
       "  'profit_sum': 0,\n",
       "  'profit_ratio': nan,\n",
       "  'investment_total': 0},\n",
       " {'combination': 12,\n",
       "  'scaler': 'MinMaxScaler',\n",
       "  'classifier': 'AdaBoostClassifier',\n",
       "  'profit_sum': 518.0720767425748,\n",
       "  'profit_ratio': 0.012132835520903391,\n",
       "  'investment_total': 42700},\n",
       " {'combination': 13,\n",
       "  'scaler': 'MinMaxScaler',\n",
       "  'classifier': 'MLPClassifier',\n",
       "  'profit_sum': 788.3699996159739,\n",
       "  'profit_ratio': 0.021192741925160588,\n",
       "  'investment_total': 37200},\n",
       " {'combination': 14,\n",
       "  'scaler': 'MinMaxScaler',\n",
       "  'classifier': 'MLPClassifier',\n",
       "  'profit_sum': 25.136901612390716,\n",
       "  'profit_ratio': 0.000610118971174532,\n",
       "  'investment_total': 41200},\n",
       " {'combination': 15,\n",
       "  'scaler': 'MinMaxScaler',\n",
       "  'classifier': 'MLPClassifier',\n",
       "  'profit_sum': 779.4603335565839,\n",
       "  'profit_ratio': 0.026877942536433927,\n",
       "  'investment_total': 29000},\n",
       " {'combination': 16,\n",
       "  'scaler': 'MinMaxScaler',\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'profit_sum': -52.64423362139314,\n",
       "  'profit_ratio': -0.0018602202693071782,\n",
       "  'investment_total': 28300},\n",
       " {'combination': 17,\n",
       "  'scaler': 'MinMaxScaler',\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'profit_sum': 16.611288991450493,\n",
       "  'profit_ratio': 0.0007285653066425655,\n",
       "  'investment_total': 22800},\n",
       " {'combination': 18,\n",
       "  'scaler': 'MinMaxScaler',\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'profit_sum': -101.44740500794933,\n",
       "  'profit_ratio': -0.010247212627065589,\n",
       "  'investment_total': 9900},\n",
       " {'combination': 19,\n",
       "  'scaler': 'StandardScaler',\n",
       "  'classifier': 'KNeighborsClassifier',\n",
       "  'profit_sum': 1568.8411309290796,\n",
       "  'profit_ratio': 0.01867668013010809,\n",
       "  'investment_total': 84000},\n",
       " {'combination': 20,\n",
       "  'scaler': 'StandardScaler',\n",
       "  'classifier': 'KNeighborsClassifier',\n",
       "  'profit_sum': -234.88668127528405,\n",
       "  'profit_ratio': -0.0029960035876949497,\n",
       "  'investment_total': 78400},\n",
       " {'combination': 21,\n",
       "  'scaler': 'StandardScaler',\n",
       "  'classifier': 'KNeighborsClassifier',\n",
       "  'profit_sum': -824.0434600738017,\n",
       "  'profit_ratio': -0.011105707009080886,\n",
       "  'investment_total': 74200},\n",
       " {'combination': 22,\n",
       "  'scaler': 'StandardScaler',\n",
       "  'classifier': 'GaussianNB',\n",
       "  'profit_sum': 3325.0590676731263,\n",
       "  'profit_ratio': 0.0528626242873311,\n",
       "  'investment_total': 62900},\n",
       " {'combination': 23,\n",
       "  'scaler': 'StandardScaler',\n",
       "  'classifier': 'GaussianNB',\n",
       "  'profit_sum': 3199.267784725779,\n",
       "  'profit_ratio': 0.05244701286435704,\n",
       "  'investment_total': 61000},\n",
       " {'combination': 24,\n",
       "  'scaler': 'StandardScaler',\n",
       "  'classifier': 'GaussianNB',\n",
       "  'profit_sum': 3424.9432153415564,\n",
       "  'profit_ratio': 0.05445060755709947,\n",
       "  'investment_total': 62900},\n",
       " {'combination': 25,\n",
       "  'scaler': 'StandardScaler',\n",
       "  'classifier': 'RandomForestClassifier',\n",
       "  'profit_sum': 426.00897310674077,\n",
       "  'profit_ratio': 0.013354513263534193,\n",
       "  'investment_total': 31900},\n",
       " {'combination': 26,\n",
       "  'scaler': 'StandardScaler',\n",
       "  'classifier': 'RandomForestClassifier',\n",
       "  'profit_sum': 1573.4033285343796,\n",
       "  'profit_ratio': 0.04469895819699942,\n",
       "  'investment_total': 35200},\n",
       " {'combination': 27,\n",
       "  'scaler': 'StandardScaler',\n",
       "  'classifier': 'RandomForestClassifier',\n",
       "  'profit_sum': 1425.5654295727293,\n",
       "  'profit_ratio': 0.02868340904572896,\n",
       "  'investment_total': 49700},\n",
       " {'combination': 28,\n",
       "  'scaler': 'StandardScaler',\n",
       "  'classifier': 'AdaBoostClassifier',\n",
       "  'profit_sum': 264.1982387280452,\n",
       "  'profit_ratio': 0.012403673179720433,\n",
       "  'investment_total': 21300},\n",
       " {'combination': 29,\n",
       "  'scaler': 'StandardScaler',\n",
       "  'classifier': 'AdaBoostClassifier',\n",
       "  'profit_sum': 0,\n",
       "  'profit_ratio': nan,\n",
       "  'investment_total': 0},\n",
       " {'combination': 30,\n",
       "  'scaler': 'StandardScaler',\n",
       "  'classifier': 'AdaBoostClassifier',\n",
       "  'profit_sum': 518.0720767425748,\n",
       "  'profit_ratio': 0.012132835520903391,\n",
       "  'investment_total': 42700},\n",
       " {'combination': 31,\n",
       "  'scaler': 'StandardScaler',\n",
       "  'classifier': 'MLPClassifier',\n",
       "  'profit_sum': 1302.2862459483085,\n",
       "  'profit_ratio': 0.028875526517700853,\n",
       "  'investment_total': 45100},\n",
       " {'combination': 32,\n",
       "  'scaler': 'StandardScaler',\n",
       "  'classifier': 'MLPClassifier',\n",
       "  'profit_sum': 2596.739497198572,\n",
       "  'profit_ratio': 0.049556097274781906,\n",
       "  'investment_total': 52400},\n",
       " {'combination': 33,\n",
       "  'scaler': 'StandardScaler',\n",
       "  'classifier': 'MLPClassifier',\n",
       "  'profit_sum': 796.6753576919089,\n",
       "  'profit_ratio': 0.02289297004861807,\n",
       "  'investment_total': 34800},\n",
       " {'combination': 34,\n",
       "  'scaler': 'StandardScaler',\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'profit_sum': 62.93343229246523,\n",
       "  'profit_ratio': 0.0021118601440424573,\n",
       "  'investment_total': 29800},\n",
       " {'combination': 35,\n",
       "  'scaler': 'StandardScaler',\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'profit_sum': -99.74628353972639,\n",
       "  'profit_ratio': -0.0033698068763421078,\n",
       "  'investment_total': 29600},\n",
       " {'combination': 36,\n",
       "  'scaler': 'StandardScaler',\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'profit_sum': -212.36003865077942,\n",
       "  'profit_ratio': -0.008013586364180356,\n",
       "  'investment_total': 26500},\n",
       " {'combination': 37,\n",
       "  'scaler': 'RobustScaler',\n",
       "  'classifier': 'KNeighborsClassifier',\n",
       "  'profit_sum': 1032.5507506069707,\n",
       "  'profit_ratio': 0.012306921938104539,\n",
       "  'investment_total': 83900},\n",
       " {'combination': 38,\n",
       "  'scaler': 'RobustScaler',\n",
       "  'classifier': 'KNeighborsClassifier',\n",
       "  'profit_sum': 3442.4610556341113,\n",
       "  'profit_ratio': 0.04476542335024852,\n",
       "  'investment_total': 76900},\n",
       " {'combination': 39,\n",
       "  'scaler': 'RobustScaler',\n",
       "  'classifier': 'KNeighborsClassifier',\n",
       "  'profit_sum': -1556.9000579386723,\n",
       "  'profit_ratio': -0.021897328522344196,\n",
       "  'investment_total': 71100},\n",
       " {'combination': 40,\n",
       "  'scaler': 'RobustScaler',\n",
       "  'classifier': 'GaussianNB',\n",
       "  'profit_sum': 3325.0590676731263,\n",
       "  'profit_ratio': 0.0528626242873311,\n",
       "  'investment_total': 62900},\n",
       " {'combination': 41,\n",
       "  'scaler': 'RobustScaler',\n",
       "  'classifier': 'GaussianNB',\n",
       "  'profit_sum': -26.409790558643103,\n",
       "  'profit_ratio': -0.018864136113316502,\n",
       "  'investment_total': 1400},\n",
       " {'combination': 42,\n",
       "  'scaler': 'RobustScaler',\n",
       "  'classifier': 'GaussianNB',\n",
       "  'profit_sum': 2276.2511543022333,\n",
       "  'profit_ratio': 0.05690627885755583,\n",
       "  'investment_total': 40000},\n",
       " {'combination': 43,\n",
       "  'scaler': 'RobustScaler',\n",
       "  'classifier': 'RandomForestClassifier',\n",
       "  'profit_sum': 827.863467270231,\n",
       "  'profit_ratio': 0.02571004556739848,\n",
       "  'investment_total': 32200},\n",
       " {'combination': 44,\n",
       "  'scaler': 'RobustScaler',\n",
       "  'classifier': 'RandomForestClassifier',\n",
       "  'profit_sum': 1932.1399491682682,\n",
       "  'profit_ratio': 0.05427359407776034,\n",
       "  'investment_total': 35600},\n",
       " {'combination': 45,\n",
       "  'scaler': 'RobustScaler',\n",
       "  'classifier': 'RandomForestClassifier',\n",
       "  'profit_sum': 2577.8477447337505,\n",
       "  'profit_ratio': 0.05250199072777496,\n",
       "  'investment_total': 49100},\n",
       " {'combination': 46,\n",
       "  'scaler': 'RobustScaler',\n",
       "  'classifier': 'AdaBoostClassifier',\n",
       "  'profit_sum': 264.1982387280452,\n",
       "  'profit_ratio': 0.012403673179720433,\n",
       "  'investment_total': 21300},\n",
       " {'combination': 47,\n",
       "  'scaler': 'RobustScaler',\n",
       "  'classifier': 'AdaBoostClassifier',\n",
       "  'profit_sum': 0,\n",
       "  'profit_ratio': nan,\n",
       "  'investment_total': 0},\n",
       " {'combination': 48,\n",
       "  'scaler': 'RobustScaler',\n",
       "  'classifier': 'AdaBoostClassifier',\n",
       "  'profit_sum': 518.0720767425748,\n",
       "  'profit_ratio': 0.012132835520903391,\n",
       "  'investment_total': 42700},\n",
       " {'combination': 49,\n",
       "  'scaler': 'RobustScaler',\n",
       "  'classifier': 'MLPClassifier',\n",
       "  'profit_sum': 1708.1074628131246,\n",
       "  'profit_ratio': 0.04096180965978716,\n",
       "  'investment_total': 41700},\n",
       " {'combination': 50,\n",
       "  'scaler': 'RobustScaler',\n",
       "  'classifier': 'MLPClassifier',\n",
       "  'profit_sum': 654.9906001788006,\n",
       "  'profit_ratio': 0.015595014289971443,\n",
       "  'investment_total': 42000},\n",
       " {'combination': 51,\n",
       "  'scaler': 'RobustScaler',\n",
       "  'classifier': 'MLPClassifier',\n",
       "  'profit_sum': 425.8069435773609,\n",
       "  'profit_ratio': 0.010410927715827896,\n",
       "  'investment_total': 40900},\n",
       " {'combination': 52,\n",
       "  'scaler': 'RobustScaler',\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'profit_sum': -530.2900498108388,\n",
       "  'profit_ratio': -0.016942174115362262,\n",
       "  'investment_total': 31300},\n",
       " {'combination': 53,\n",
       "  'scaler': 'RobustScaler',\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'profit_sum': 83.65121412524104,\n",
       "  'profit_ratio': 0.0026984262621045497,\n",
       "  'investment_total': 31000},\n",
       " {'combination': 54,\n",
       "  'scaler': 'RobustScaler',\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'profit_sum': 373.701307284292,\n",
       "  'profit_ratio': 0.014209175181912243,\n",
       "  'investment_total': 26300}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "723008da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_viz = pd.DataFrame(results_a)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.bar(results_viz['combination'], results_viz['profit_ratio'], color='b')\n",
    "plt.xlabel('Combination')\n",
    "plt.ylabel('Profit Ratio')\n",
    "plt.title('Profit Ratio for Each Combination')\n",
    "plt.xticks(results_viz['combination'])\n",
    "\n",
    "for index, value in enumerate(results_viz['profit_ratio']):\n",
    "    plt.text(results_viz['combination'][index], value, f'{value:.3f}', horizontalalignment='center', verticalalignment='bottom')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c517552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'combination': 12, 'scaler': 'MinMaxScaler', 'classifier': 'AdaBoostClassifier', 'profit_sum': 0, 'profit_ratio': nan, 'investment_total': 0}\n",
      "{'combination': 29, 'scaler': 'StandardScaler', 'classifier': 'RandomForestClassifier', 'profit_sum': 3773.2489024236716, 'profit_ratio': 0.10842669259838136, 'investment_total': 34800}\n",
      "{'combination': 26, 'scaler': 'StandardScaler', 'classifier': 'MLPClassifier', 'profit_sum': 3364.9434539618915, 'profit_ratio': 0.08167338480490027, 'investment_total': 41200}\n",
      "{'combination': 10, 'scaler': 'MinMaxScaler', 'classifier': 'RandomForestClassifier', 'profit_sum': 2814.353708510015, 'profit_ratio': 0.07995323035539816, 'investment_total': 35200}\n",
      "{'combination': 31, 'scaler': 'StandardScaler', 'classifier': 'AdaBoostClassifier', 'profit_sum': 0, 'profit_ratio': nan, 'investment_total': 0}\n",
      "{'combination': 49, 'scaler': 'RobustScaler', 'classifier': 'RandomForestClassifier', 'profit_sum': 3706.15189435701, 'profit_ratio': 0.07579042728746442, 'investment_total': 48900}\n",
      "{'combination': 48, 'scaler': 'RobustScaler', 'classifier': 'RandomForestClassifier', 'profit_sum': 2270.4526070901466, 'profit_ratio': 0.06377675862612771, 'investment_total': 35600}\n",
      "{'combination': 36, 'scaler': 'StandardScaler', 'classifier': 'GaussianNB', 'profit_sum': 3424.9432153415564, 'profit_ratio': 0.05445060755709947, 'investment_total': 62900}\n",
      "{'combination': 16, 'scaler': 'MinMaxScaler', 'classifier': 'GaussianNB', 'profit_sum': 2946.8743473509358, 'profit_ratio': 0.05407108894221901, 'investment_total': 54500}\n",
      "{'combination': 3, 'scaler': 'MinMaxScaler', 'classifier': 'GaussianNB', 'profit_sum': 3325.0590676731263, 'profit_ratio': 0.0528626242873311, 'investment_total': 62900}\n"
     ]
    }
   ],
   "source": [
    "# Sort the results list by profit_ratio in descending order\n",
    "sorted_results = sorted(results_a, key=lambda x: x['profit_ratio'], reverse=True)\n",
    "\n",
    "# Filter the top 10 models\n",
    "top_10_models = sorted_results[:10]\n",
    "\n",
    "# Print the top 10 models\n",
    "for model in top_10_models:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a8298bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3442.4610556341113"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(profit_sums_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4abcf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -8       0.00      0.00      0.00         0\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.15      0.06      0.09       116\n",
      "          -1       0.28      0.15      0.19       274\n",
      "           0       0.27      0.74      0.40       401\n",
      "           1       0.23      0.03      0.05       348\n",
      "           2       0.17      0.11      0.13       174\n",
      "           3       0.14      0.01      0.02        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.07      0.10      0.08        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.24      1580\n",
      "   macro avg       0.08      0.07      0.06      1580\n",
      "weighted avg       0.21      0.24      0.17      1580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(max(classification_reports_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7307b1",
   "metadata": {},
   "source": [
    "# MODEL B: 1 - 0 - 2 - WINNER PREDICTION - By Result Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72ab93aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_102(df):\n",
    "    #copy the df just in case\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    #Drop unnecessary columns\n",
    "    df_processed.drop(['League', 'team1', 'team2','point_team1', 'point_team2','spi_1','spi_2'], axis=1, inplace=True)\n",
    "    \n",
    "    #Alter values to be able to make classification models predict the result rather than score difference\n",
    "    df_processed.loc[df_processed['scor_diff'] == 0 , 'scor_diff'] = 0\n",
    "    df_processed.loc[df_processed['scor_diff'] > 0 , 'scor_diff'] = 1\n",
    "    df_processed.loc[df_processed['scor_diff'] < 0, 'scor_diff'] = 2\n",
    "\n",
    "    #Define feature and target columns\n",
    "    X = df_processed.drop(['scor_diff'], axis=1)\n",
    "    y = df_processed['scor_diff']\n",
    "\n",
    "    # Sort the DataFrame by date columns in descending order\n",
    "    df_sorted = df_processed.sort_values(by=['Year', 'Month', 'Week_ofday'], ascending=True)\n",
    "    \n",
    "    # Calculate the indices for the train-test split\n",
    "    train_size = int(0.75 * len(df_sorted))\n",
    "    train_indices = df_sorted.index[:train_size]\n",
    "    test_indices = df_sorted.index[train_size:]\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train = X.loc[train_indices]\n",
    "    X_test = X.loc[test_indices]\n",
    "    y_train = y.loc[train_indices]\n",
    "    y_test = y.loc[test_indices]\n",
    "    \n",
    "    # Create a list of all possible combinations of hyperparameters\n",
    "    scaling = [MinMaxScaler(), StandardScaler(),RobustScaler()]\n",
    "    classifier = [\n",
    "        KNeighborsClassifier(3),\n",
    "        DecisionTreeClassifier(max_depth=5),\n",
    "        GaussianNB(),\n",
    "        RandomForestClassifier(max_depth=5, n_estimators=300),\n",
    "        AdaBoostClassifier(learning_rate=0.1),\n",
    "        LogisticRegression(),\n",
    "        MLPClassifier(hidden_layer_sizes=(10, 5), learning_rate_init=0.01),\n",
    "        MLPClassifier(hidden_layer_sizes=(20, 10), learning_rate_init=0.001),\n",
    "        MLPClassifier(hidden_layer_sizes=(50, 25), learning_rate_init=0.0001),\n",
    "        RandomForestClassifier(max_depth=10, n_estimators=500),\n",
    "        RandomForestClassifier(max_depth=20, n_estimators=1000),\n",
    "        AdaBoostClassifier(learning_rate=0.01, n_estimators=100),\n",
    "        AdaBoostClassifier(learning_rate=0.1, n_estimators=500),\n",
    "        KNeighborsClassifier(5),\n",
    "        KNeighborsClassifier(7),\n",
    "        GaussianNB(var_smoothing=0.1),\n",
    "        GaussianNB(var_smoothing=0.01),\n",
    "        LogisticRegression(C=0.1),\n",
    "        LogisticRegression(C=0.01)\n",
    "    ]\n",
    "    #Save the combination of scalers and classifiers\n",
    "    combinations = list(itertools.product( scaling, classifier))\n",
    "    # Initialize empty lists to store sums of profit and classification reports\n",
    "    profit_sums = []\n",
    "    classification_reports = []\n",
    "    \n",
    "    \n",
    "    #Put the pipeline in  for loop to see all the profits made by all combination\n",
    "    for i, combo in enumerate(combinations):\n",
    "        # Create a pipeline\n",
    "        pipe = Pipeline([\n",
    "            ('scaling', combo[0]),\n",
    "            ('classifier', combo[1])\n",
    "        ])\n",
    "\n",
    "        # Fit the model\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions on test set\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        \n",
    "        # Calculate classification report\n",
    "        clas_report = classification_report(y_test, y_pred)\n",
    "        classification_reports.append(clas_report)\n",
    "        \n",
    "        df_result = df.loc[y_test.index].copy()\n",
    "        df_result['y_prediction'] = y_pred\n",
    "\n",
    "        df_result_step2 = df_result.copy()\n",
    "        \n",
    "        df_result_step2['True_False'] = 0  # Initialize with 0 (incorrect prediction)\n",
    "        \n",
    "        ########################################\n",
    "        # LOST BET\n",
    "        df_result_step2.loc[((df_result_step2['scor_diff'] == 1) & (df_result_step2['y_prediction'] != 1)) |\n",
    "                            ((df_result_step2['scor_diff'] == 0) & (df_result_step2['y_prediction'] != 0)) |\n",
    "                            ((df_result_step2['scor_diff'] == 2) & (df_result_step2['y_prediction'] != 2)), 'True_False'] = 0\n",
    "        \n",
    "        # WON BET\n",
    "        df_result_step2.loc[((df_result_step2['scor_diff'] == 1) & (df_result_step2['y_prediction'] == 1)) |\n",
    "                            ((df_result_step2['scor_diff'] == 0) & (df_result_step2['y_prediction'] == 0)) |\n",
    "                            ((df_result_step2['scor_diff'] == 2) & (df_result_step2['y_prediction'] == 2)), 'True_False'] = 1\n",
    "        df_result_step2['True_False'] = df_result_step2['True_False'].astype(int)\n",
    "        \n",
    "        ###########################################\n",
    "        df_result_step2 = probability_to_reg_dnb_odds(df_result_step2)\n",
    "        df_result_step2['profit'] = df_result_step2.apply(calculate_value_winlose, axis=1)\n",
    "        \n",
    "        # Calculate the sum of 'profit' column\n",
    "        profit_sum = df_result_step2['profit'].sum()\n",
    "        profit_sums.append(profit_sum)\n",
    "\n",
    "        #Print the metrics\n",
    "        print(f\"Combination {i+1}: {combo} - Profit Sum: {profit_sum} - Profit ratio: {profit_sum/(len(df_result_step2)*100)}\")\n",
    "        print(f\"Classification Report for Combination {i+1}:\\n{clas_report}\\n\")\n",
    "        print(df_result['y_prediction'].value_counts())   \n",
    "        \n",
    "        \n",
    "    return profit_sums, classification_reports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0146eb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 1: (MinMaxScaler(), KNeighborsClassifier(n_neighbors=3)) - Profit Sum: -58857.789000739635 - Profit ratio: -0.3725176519034154\n",
      "Classification Report for Combination 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.40      0.32       401\n",
      "           1       0.54      0.44      0.49       690\n",
      "           2       0.44      0.38      0.41       489\n",
      "\n",
      "    accuracy                           0.41      1580\n",
      "   macro avg       0.42      0.40      0.40      1580\n",
      "weighted avg       0.44      0.41      0.42      1580\n",
      "\n",
      "\n",
      "0    597\n",
      "1    564\n",
      "2    419\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 2: (MinMaxScaler(), DecisionTreeClassifier(max_depth=5)) - Profit Sum: -94546.77632332919 - Profit ratio: -0.5983973185020834\n",
      "Classification Report for Combination 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.06      0.09       401\n",
      "           1       0.54      0.77      0.63       690\n",
      "           2       0.47      0.48      0.48       489\n",
      "\n",
      "    accuracy                           0.50      1580\n",
      "   macro avg       0.42      0.44      0.40      1580\n",
      "weighted avg       0.45      0.50      0.45      1580\n",
      "\n",
      "\n",
      "1    985\n",
      "2    508\n",
      "0     87\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 3: (MinMaxScaler(), GaussianNB()) - Profit Sum: -66956.29096923152 - Profit ratio: -0.42377399347614886\n",
      "Classification Report for Combination 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.45      0.35       401\n",
      "           1       0.66      0.42      0.51       690\n",
      "           2       0.50      0.51      0.51       489\n",
      "\n",
      "    accuracy                           0.46      1580\n",
      "   macro avg       0.48      0.46      0.45      1580\n",
      "weighted avg       0.51      0.46      0.47      1580\n",
      "\n",
      "\n",
      "0    640\n",
      "2    503\n",
      "1    437\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 4: (MinMaxScaler(), RandomForestClassifier(max_depth=5, n_estimators=300)) - Profit Sum: -100060.96207395477 - Profit ratio: -0.6332972283161694\n",
      "Classification Report for Combination 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       401\n",
      "           1       0.54      0.80      0.65       690\n",
      "           2       0.48      0.55      0.52       489\n",
      "\n",
      "    accuracy                           0.52      1580\n",
      "   macro avg       0.34      0.45      0.39      1580\n",
      "weighted avg       0.39      0.52      0.44      1580\n",
      "\n",
      "\n",
      "1    1022\n",
      "2     558\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 5: (MinMaxScaler(), AdaBoostClassifier(learning_rate=0.1)) - Profit Sum: -102853.414617515 - Profit ratio: -0.650970978591867\n",
      "Classification Report for Combination 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       401\n",
      "           1       0.54      0.79      0.64       690\n",
      "           2       0.47      0.55      0.51       489\n",
      "\n",
      "    accuracy                           0.51      1580\n",
      "   macro avg       0.34      0.45      0.38      1580\n",
      "weighted avg       0.38      0.51      0.44      1580\n",
      "\n",
      "\n",
      "1    1010\n",
      "2     570\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 6: (MinMaxScaler(), LogisticRegression()) - Profit Sum: -95016.59456027289 - Profit ratio: -0.6013708516472968\n",
      "Classification Report for Combination 6:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.10      0.15       401\n",
      "           1       0.58      0.70      0.63       690\n",
      "           2       0.47      0.60      0.53       489\n",
      "\n",
      "    accuracy                           0.52      1580\n",
      "   macro avg       0.46      0.47      0.44      1580\n",
      "weighted avg       0.48      0.52      0.48      1580\n",
      "\n",
      "\n",
      "1    835\n",
      "2    621\n",
      "0    124\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 7: (MinMaxScaler(), MLPClassifier(hidden_layer_sizes=(10, 5), learning_rate_init=0.01)) - Profit Sum: -74096.74500557617 - Profit ratio: -0.46896674054162135\n",
      "Classification Report for Combination 7:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.29      0.28       401\n",
      "           1       0.58      0.66      0.62       690\n",
      "           2       0.51      0.39      0.44       489\n",
      "\n",
      "    accuracy                           0.48      1580\n",
      "   macro avg       0.45      0.45      0.45      1580\n",
      "weighted avg       0.48      0.48      0.48      1580\n",
      "\n",
      "\n",
      "1    790\n",
      "0    413\n",
      "2    377\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 8: (MinMaxScaler(), MLPClassifier(hidden_layer_sizes=(20, 10))) - Profit Sum: -79833.52252460326 - Profit ratio: -0.5052754590164763\n",
      "Classification Report for Combination 8:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.24      0.26       401\n",
      "           1       0.58      0.63      0.61       690\n",
      "           2       0.48      0.50      0.49       489\n",
      "\n",
      "    accuracy                           0.49      1580\n",
      "   macro avg       0.45      0.46      0.45      1580\n",
      "weighted avg       0.48      0.49      0.48      1580\n",
      "\n",
      "\n",
      "1    748\n",
      "2    509\n",
      "0    323\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 9: (MinMaxScaler(), MLPClassifier(hidden_layer_sizes=(50, 25), learning_rate_init=0.0001)) - Profit Sum: -101675.98567129279 - Profit ratio: -0.6435188966537518\n",
      "Classification Report for Combination 9:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.05      0.08       401\n",
      "           1       0.56      0.73      0.63       690\n",
      "           2       0.48      0.57      0.52       489\n",
      "\n",
      "    accuracy                           0.51      1580\n",
      "   macro avg       0.42      0.45      0.41      1580\n",
      "weighted avg       0.45      0.51      0.46      1580\n",
      "\n",
      "\n",
      "1    910\n",
      "2    579\n",
      "0     91\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 10: (MinMaxScaler(), RandomForestClassifier(max_depth=10, n_estimators=500)) - Profit Sum: -95621.5526279356 - Profit ratio: -0.6051997001768076\n",
      "Classification Report for Combination 10:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.06      0.10       401\n",
      "           1       0.56      0.76      0.64       690\n",
      "           2       0.47      0.55      0.51       489\n",
      "\n",
      "    accuracy                           0.51      1580\n",
      "   macro avg       0.44      0.45      0.42      1580\n",
      "weighted avg       0.47      0.51      0.46      1580\n",
      "\n",
      "\n",
      "1    927\n",
      "2    568\n",
      "0     85\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 11: (MinMaxScaler(), RandomForestClassifier(max_depth=20, n_estimators=1000)) - Profit Sum: -90136.01592170609 - Profit ratio: -0.5704811134285195\n",
      "Classification Report for Combination 11:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.13      0.17       401\n",
      "           1       0.57      0.67      0.61       690\n",
      "           2       0.46      0.52      0.49       489\n",
      "\n",
      "    accuracy                           0.49      1580\n",
      "   macro avg       0.42      0.44      0.42      1580\n",
      "weighted avg       0.45      0.49      0.46      1580\n",
      "\n",
      "\n",
      "1    812\n",
      "2    556\n",
      "0    212\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 12: (MinMaxScaler(), AdaBoostClassifier(learning_rate=0.01, n_estimators=100)) - Profit Sum: -100986.77746833453 - Profit ratio: -0.6391568194198388\n",
      "Classification Report for Combination 12:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       401\n",
      "           1       0.53      0.80      0.64       690\n",
      "           2       0.48      0.52      0.50       489\n",
      "\n",
      "    accuracy                           0.51      1580\n",
      "   macro avg       0.34      0.44      0.38      1580\n",
      "weighted avg       0.38      0.51      0.43      1580\n",
      "\n",
      "\n",
      "1    1051\n",
      "2     529\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 13: (MinMaxScaler(), AdaBoostClassifier(learning_rate=0.1, n_estimators=500)) - Profit Sum: -98030.55986765533 - Profit ratio: -0.6204465814408565\n",
      "Classification Report for Combination 13:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.06      0.10       401\n",
      "           1       0.56      0.75      0.64       690\n",
      "           2       0.47      0.55      0.51       489\n",
      "\n",
      "    accuracy                           0.51      1580\n",
      "   macro avg       0.44      0.45      0.42      1580\n",
      "weighted avg       0.46      0.51      0.46      1580\n",
      "\n",
      "\n",
      "1    917\n",
      "2    577\n",
      "0     86\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 14: (MinMaxScaler(), KNeighborsClassifier()) - Profit Sum: -62294.16312032985 - Profit ratio: -0.3942668551919611\n",
      "Classification Report for Combination 14:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.34      0.30       401\n",
      "           1       0.50      0.52      0.51       690\n",
      "           2       0.44      0.32      0.37       489\n",
      "\n",
      "    accuracy                           0.42      1580\n",
      "   macro avg       0.41      0.40      0.40      1580\n",
      "weighted avg       0.43      0.42      0.42      1580\n",
      "\n",
      "\n",
      "1    718\n",
      "0    506\n",
      "2    356\n",
      "Name: y_prediction, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 15: (MinMaxScaler(), KNeighborsClassifier(n_neighbors=7)) - Profit Sum: -71987.15456841879 - Profit ratio: -0.4556149023317645\n",
      "Classification Report for Combination 15:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.29      0.29       401\n",
      "           1       0.53      0.59      0.56       690\n",
      "           2       0.44      0.39      0.41       489\n",
      "\n",
      "    accuracy                           0.45      1580\n",
      "   macro avg       0.42      0.42      0.42      1580\n",
      "weighted avg       0.44      0.45      0.45      1580\n",
      "\n",
      "\n",
      "1    756\n",
      "2    433\n",
      "0    391\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 16: (MinMaxScaler(), GaussianNB(var_smoothing=0.1)) - Profit Sum: -65600.16849509426 - Profit ratio: -0.4151909398423687\n",
      "Classification Report for Combination 16:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.45      0.35       401\n",
      "           1       0.66      0.43      0.52       690\n",
      "           2       0.49      0.52      0.51       489\n",
      "\n",
      "    accuracy                           0.46      1580\n",
      "   macro avg       0.48      0.47      0.46      1580\n",
      "weighted avg       0.52      0.46      0.48      1580\n",
      "\n",
      "\n",
      "0    614\n",
      "2    512\n",
      "1    454\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 17: (MinMaxScaler(), GaussianNB(var_smoothing=0.01)) - Profit Sum: -66393.07790711269 - Profit ratio: -0.42020935384248537\n",
      "Classification Report for Combination 17:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.45      0.35       401\n",
      "           1       0.66      0.42      0.51       690\n",
      "           2       0.50      0.51      0.51       489\n",
      "\n",
      "    accuracy                           0.46      1580\n",
      "   macro avg       0.48      0.46      0.46      1580\n",
      "weighted avg       0.51      0.46      0.47      1580\n",
      "\n",
      "\n",
      "0    639\n",
      "2    502\n",
      "1    439\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 18: (MinMaxScaler(), LogisticRegression(C=0.1)) - Profit Sum: -96606.47654491369 - Profit ratio: -0.6114333958538841\n",
      "Classification Report for Combination 18:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.08      0.13       401\n",
      "           1       0.57      0.72      0.64       690\n",
      "           2       0.47      0.61      0.53       489\n",
      "\n",
      "    accuracy                           0.52      1580\n",
      "   macro avg       0.47      0.47      0.43      1580\n",
      "weighted avg       0.49      0.52      0.48      1580\n",
      "\n",
      "\n",
      "1    866\n",
      "2    626\n",
      "0     88\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 19: (MinMaxScaler(), LogisticRegression(C=0.01)) - Profit Sum: -100176.39582614599 - Profit ratio: -0.6340278216844683\n",
      "Classification Report for Combination 19:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.00      0.00       401\n",
      "           1       0.55      0.82      0.66       690\n",
      "           2       0.50      0.57      0.54       489\n",
      "\n",
      "    accuracy                           0.54      1580\n",
      "   macro avg       0.52      0.46      0.40      1580\n",
      "weighted avg       0.52      0.54      0.46      1580\n",
      "\n",
      "\n",
      "1    1017\n",
      "2     561\n",
      "0       2\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 20: (StandardScaler(), KNeighborsClassifier(n_neighbors=3)) - Profit Sum: -53561.209500729994 - Profit ratio: -0.33899499684006323\n",
      "Classification Report for Combination 20:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.43      0.35       401\n",
      "           1       0.55      0.46      0.50       690\n",
      "           2       0.44      0.38      0.41       489\n",
      "\n",
      "    accuracy                           0.43      1580\n",
      "   macro avg       0.43      0.42      0.42      1580\n",
      "weighted avg       0.45      0.43      0.43      1580\n",
      "\n",
      "\n",
      "0    583\n",
      "1    578\n",
      "2    419\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 21: (StandardScaler(), DecisionTreeClassifier(max_depth=5)) - Profit Sum: -94376.67936806468 - Profit ratio: -0.5973207554940803\n",
      "Classification Report for Combination 21:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.06      0.09       401\n",
      "           1       0.54      0.77      0.63       690\n",
      "           2       0.47      0.48      0.48       489\n",
      "\n",
      "    accuracy                           0.50      1580\n",
      "   macro avg       0.42      0.44      0.40      1580\n",
      "weighted avg       0.45      0.50      0.45      1580\n",
      "\n",
      "\n",
      "1    986\n",
      "2    507\n",
      "0     87\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 22: (StandardScaler(), GaussianNB()) - Profit Sum: -66956.29096923152 - Profit ratio: -0.42377399347614886\n",
      "Classification Report for Combination 22:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.45      0.35       401\n",
      "           1       0.66      0.42      0.51       690\n",
      "           2       0.50      0.51      0.51       489\n",
      "\n",
      "    accuracy                           0.46      1580\n",
      "   macro avg       0.48      0.46      0.45      1580\n",
      "weighted avg       0.51      0.46      0.47      1580\n",
      "\n",
      "\n",
      "0    640\n",
      "2    503\n",
      "1    437\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 23: (StandardScaler(), RandomForestClassifier(max_depth=5, n_estimators=300)) - Profit Sum: -100390.96505324522 - Profit ratio: -0.6353858547673749\n",
      "Classification Report for Combination 23:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       401\n",
      "           1       0.54      0.81      0.65       690\n",
      "           2       0.49      0.55      0.52       489\n",
      "\n",
      "    accuracy                           0.52      1580\n",
      "   macro avg       0.34      0.45      0.39      1580\n",
      "weighted avg       0.39      0.52      0.44      1580\n",
      "\n",
      "\n",
      "1    1026\n",
      "2     554\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 24: (StandardScaler(), AdaBoostClassifier(learning_rate=0.1)) - Profit Sum: -102853.414617515 - Profit ratio: -0.650970978591867\n",
      "Classification Report for Combination 24:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       401\n",
      "           1       0.54      0.79      0.64       690\n",
      "           2       0.47      0.55      0.51       489\n",
      "\n",
      "    accuracy                           0.51      1580\n",
      "   macro avg       0.34      0.45      0.38      1580\n",
      "weighted avg       0.38      0.51      0.44      1580\n",
      "\n",
      "\n",
      "1    1010\n",
      "2     570\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 25: (StandardScaler(), LogisticRegression()) - Profit Sum: -94278.24286417385 - Profit ratio: -0.59669773964667\n",
      "Classification Report for Combination 25:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.11      0.16       401\n",
      "           1       0.58      0.70      0.63       690\n",
      "           2       0.47      0.60      0.53       489\n",
      "\n",
      "    accuracy                           0.52      1580\n",
      "   macro avg       0.46      0.47      0.44      1580\n",
      "weighted avg       0.48      0.52      0.48      1580\n",
      "\n",
      "\n",
      "1    832\n",
      "2    619\n",
      "0    129\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 26: (StandardScaler(), MLPClassifier(hidden_layer_sizes=(10, 5), learning_rate_init=0.01)) - Profit Sum: -83725.4561405463 - Profit ratio: -0.5299079502566222\n",
      "Classification Report for Combination 26:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.23      0.25       401\n",
      "           1       0.57      0.53      0.55       690\n",
      "           2       0.45      0.56      0.50       489\n",
      "\n",
      "    accuracy                           0.46      1580\n",
      "   macro avg       0.43      0.44      0.43      1580\n",
      "weighted avg       0.46      0.46      0.46      1580\n",
      "\n",
      "\n",
      "1    637\n",
      "2    610\n",
      "0    333\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 27: (StandardScaler(), MLPClassifier(hidden_layer_sizes=(20, 10))) - Profit Sum: -78570.78352472617 - Profit ratio: -0.4972834400299125\n",
      "Classification Report for Combination 27:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.22      0.25       401\n",
      "           1       0.53      0.59      0.56       690\n",
      "           2       0.45      0.46      0.46       489\n",
      "\n",
      "    accuracy                           0.46      1580\n",
      "   macro avg       0.42      0.42      0.42      1580\n",
      "weighted avg       0.44      0.46      0.45      1580\n",
      "\n",
      "\n",
      "1    768\n",
      "2    504\n",
      "0    308\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 28: (StandardScaler(), MLPClassifier(hidden_layer_sizes=(50, 25), learning_rate_init=0.0001)) - Profit Sum: -90171.56363940865 - Profit ratio: -0.570706098983599\n",
      "Classification Report for Combination 28:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.16      0.20       401\n",
      "           1       0.58      0.65      0.61       690\n",
      "           2       0.45      0.53      0.49       489\n",
      "\n",
      "    accuracy                           0.49      1580\n",
      "   macro avg       0.43      0.45      0.43      1580\n",
      "weighted avg       0.46      0.49      0.47      1580\n",
      "\n",
      "\n",
      "1    763\n",
      "2    575\n",
      "0    242\n",
      "Name: y_prediction, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 29: (StandardScaler(), RandomForestClassifier(max_depth=10, n_estimators=500)) - Profit Sum: -96029.2871216764 - Profit ratio: -0.6077802982384582\n",
      "Classification Report for Combination 29:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.06      0.10       401\n",
      "           1       0.55      0.76      0.64       690\n",
      "           2       0.48      0.54      0.51       489\n",
      "\n",
      "    accuracy                           0.52      1580\n",
      "   macro avg       0.44      0.45      0.42      1580\n",
      "weighted avg       0.47      0.52      0.46      1580\n",
      "\n",
      "\n",
      "1    946\n",
      "2    553\n",
      "0     81\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 30: (StandardScaler(), RandomForestClassifier(max_depth=20, n_estimators=1000)) - Profit Sum: -90738.67693538908 - Profit ratio: -0.574295423641703\n",
      "Classification Report for Combination 30:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.13      0.17       401\n",
      "           1       0.56      0.67      0.61       690\n",
      "           2       0.46      0.52      0.49       489\n",
      "\n",
      "    accuracy                           0.49      1580\n",
      "   macro avg       0.42      0.44      0.42      1580\n",
      "weighted avg       0.45      0.49      0.46      1580\n",
      "\n",
      "\n",
      "1    818\n",
      "2    554\n",
      "0    208\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 31: (StandardScaler(), AdaBoostClassifier(learning_rate=0.01, n_estimators=100)) - Profit Sum: -100986.77746833453 - Profit ratio: -0.6391568194198388\n",
      "Classification Report for Combination 31:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       401\n",
      "           1       0.53      0.80      0.64       690\n",
      "           2       0.48      0.52      0.50       489\n",
      "\n",
      "    accuracy                           0.51      1580\n",
      "   macro avg       0.34      0.44      0.38      1580\n",
      "weighted avg       0.38      0.51      0.43      1580\n",
      "\n",
      "\n",
      "1    1051\n",
      "2     529\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 32: (StandardScaler(), AdaBoostClassifier(learning_rate=0.1, n_estimators=500)) - Profit Sum: -98030.55986765533 - Profit ratio: -0.6204465814408565\n",
      "Classification Report for Combination 32:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.06      0.10       401\n",
      "           1       0.56      0.75      0.64       690\n",
      "           2       0.47      0.55      0.51       489\n",
      "\n",
      "    accuracy                           0.51      1580\n",
      "   macro avg       0.44      0.45      0.42      1580\n",
      "weighted avg       0.46      0.51      0.46      1580\n",
      "\n",
      "\n",
      "1    917\n",
      "2    577\n",
      "0     86\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 33: (StandardScaler(), KNeighborsClassifier()) - Profit Sum: -70570.013465702 - Profit ratio: -0.44664565484621516\n",
      "Classification Report for Combination 33:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.32      0.29       401\n",
      "           1       0.51      0.53      0.52       690\n",
      "           2       0.44      0.33      0.38       489\n",
      "\n",
      "    accuracy                           0.41      1580\n",
      "   macro avg       0.40      0.39      0.39      1580\n",
      "weighted avg       0.42      0.41      0.42      1580\n",
      "\n",
      "\n",
      "1    716\n",
      "0    501\n",
      "2    363\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 34: (StandardScaler(), KNeighborsClassifier(n_neighbors=7)) - Profit Sum: -71989.28654055427 - Profit ratio: -0.45562839582629283\n",
      "Classification Report for Combination 34:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.28      0.28       401\n",
      "           1       0.53      0.57      0.55       690\n",
      "           2       0.43      0.39      0.41       489\n",
      "\n",
      "    accuracy                           0.44      1580\n",
      "   macro avg       0.41      0.41      0.41      1580\n",
      "weighted avg       0.44      0.44      0.44      1580\n",
      "\n",
      "\n",
      "1    735\n",
      "2    437\n",
      "0    408\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 35: (StandardScaler(), GaussianNB(var_smoothing=0.1)) - Profit Sum: -65048.18242874487 - Profit ratio: -0.4116973571439549\n",
      "Classification Report for Combination 35:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.46      0.35       401\n",
      "           1       0.67      0.42      0.51       690\n",
      "           2       0.50      0.51      0.50       489\n",
      "\n",
      "    accuracy                           0.46      1580\n",
      "   macro avg       0.48      0.46      0.46      1580\n",
      "weighted avg       0.52      0.46      0.47      1580\n",
      "\n",
      "\n",
      "0    645\n",
      "2    502\n",
      "1    433\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 36: (StandardScaler(), GaussianNB(var_smoothing=0.01)) - Profit Sum: -66956.29096923152 - Profit ratio: -0.42377399347614886\n",
      "Classification Report for Combination 36:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.45      0.35       401\n",
      "           1       0.66      0.42      0.51       690\n",
      "           2       0.50      0.51      0.51       489\n",
      "\n",
      "    accuracy                           0.46      1580\n",
      "   macro avg       0.48      0.46      0.45      1580\n",
      "weighted avg       0.51      0.46      0.47      1580\n",
      "\n",
      "\n",
      "0    640\n",
      "2    503\n",
      "1    437\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 37: (StandardScaler(), LogisticRegression(C=0.1)) - Profit Sum: -94625.58569154446 - Profit ratio: -0.5988961119718004\n",
      "Classification Report for Combination 37:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.10      0.16       401\n",
      "           1       0.58      0.70      0.63       690\n",
      "           2       0.47      0.60      0.53       489\n",
      "\n",
      "    accuracy                           0.52      1580\n",
      "   macro avg       0.46      0.47      0.44      1580\n",
      "weighted avg       0.48      0.52      0.48      1580\n",
      "\n",
      "\n",
      "1    833\n",
      "2    618\n",
      "0    129\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 38: (StandardScaler(), LogisticRegression(C=0.01)) - Profit Sum: -95914.97952114372 - Profit ratio: -0.607056832412302\n",
      "Classification Report for Combination 38:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.09      0.14       401\n",
      "           1       0.58      0.71      0.64       690\n",
      "           2       0.47      0.60      0.53       489\n",
      "\n",
      "    accuracy                           0.52      1580\n",
      "   macro avg       0.46      0.47      0.43      1580\n",
      "weighted avg       0.48      0.52      0.48      1580\n",
      "\n",
      "\n",
      "1    850\n",
      "2    622\n",
      "0    108\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 39: (RobustScaler(), KNeighborsClassifier(n_neighbors=3)) - Profit Sum: -57844.076191803906 - Profit ratio: -0.36610174804939183\n",
      "Classification Report for Combination 39:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.41      0.33       401\n",
      "           1       0.55      0.46      0.50       690\n",
      "           2       0.44      0.37      0.40       489\n",
      "\n",
      "    accuracy                           0.42      1580\n",
      "   macro avg       0.42      0.41      0.41      1580\n",
      "weighted avg       0.45      0.42      0.42      1580\n",
      "\n",
      "\n",
      "0    597\n",
      "1    572\n",
      "2    411\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 40: (RobustScaler(), DecisionTreeClassifier(max_depth=5)) - Profit Sum: -94546.77632332919 - Profit ratio: -0.5983973185020834\n",
      "Classification Report for Combination 40:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.06      0.09       401\n",
      "           1       0.54      0.77      0.63       690\n",
      "           2       0.47      0.48      0.48       489\n",
      "\n",
      "    accuracy                           0.50      1580\n",
      "   macro avg       0.42      0.44      0.40      1580\n",
      "weighted avg       0.45      0.50      0.45      1580\n",
      "\n",
      "\n",
      "1    985\n",
      "2    508\n",
      "0     87\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 41: (RobustScaler(), GaussianNB()) - Profit Sum: -66956.29096923152 - Profit ratio: -0.42377399347614886\n",
      "Classification Report for Combination 41:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.45      0.35       401\n",
      "           1       0.66      0.42      0.51       690\n",
      "           2       0.50      0.51      0.51       489\n",
      "\n",
      "    accuracy                           0.46      1580\n",
      "   macro avg       0.48      0.46      0.45      1580\n",
      "weighted avg       0.51      0.46      0.47      1580\n",
      "\n",
      "\n",
      "0    640\n",
      "2    503\n",
      "1    437\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 42: (RobustScaler(), RandomForestClassifier(max_depth=5, n_estimators=300)) - Profit Sum: -100341.49956729698 - Profit ratio: -0.6350727820714999\n",
      "Classification Report for Combination 42:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       401\n",
      "           1       0.54      0.80      0.65       690\n",
      "           2       0.48      0.56      0.52       489\n",
      "\n",
      "    accuracy                           0.52      1580\n",
      "   macro avg       0.34      0.45      0.39      1580\n",
      "weighted avg       0.39      0.52      0.44      1580\n",
      "\n",
      "\n",
      "1    1014\n",
      "2     566\n",
      "Name: y_prediction, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 43: (RobustScaler(), AdaBoostClassifier(learning_rate=0.1)) - Profit Sum: -102853.414617515 - Profit ratio: -0.650970978591867\n",
      "Classification Report for Combination 43:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       401\n",
      "           1       0.54      0.79      0.64       690\n",
      "           2       0.47      0.55      0.51       489\n",
      "\n",
      "    accuracy                           0.51      1580\n",
      "   macro avg       0.34      0.45      0.38      1580\n",
      "weighted avg       0.38      0.51      0.44      1580\n",
      "\n",
      "\n",
      "1    1010\n",
      "2     570\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 44: (RobustScaler(), LogisticRegression()) - Profit Sum: -94278.24286417385 - Profit ratio: -0.59669773964667\n",
      "Classification Report for Combination 44:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.11      0.16       401\n",
      "           1       0.58      0.70      0.63       690\n",
      "           2       0.47      0.60      0.53       489\n",
      "\n",
      "    accuracy                           0.52      1580\n",
      "   macro avg       0.46      0.47      0.44      1580\n",
      "weighted avg       0.48      0.52      0.48      1580\n",
      "\n",
      "\n",
      "1    832\n",
      "2    618\n",
      "0    130\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 45: (RobustScaler(), MLPClassifier(hidden_layer_sizes=(10, 5), learning_rate_init=0.01)) - Profit Sum: -98963.6015929285 - Profit ratio: -0.6263519088160032\n",
      "Classification Report for Combination 45:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.01      0.02       401\n",
      "           1       0.55      0.71      0.62       690\n",
      "           2       0.44      0.60      0.51       489\n",
      "\n",
      "    accuracy                           0.50      1580\n",
      "   macro avg       0.38      0.44      0.38      1580\n",
      "weighted avg       0.42      0.50      0.44      1580\n",
      "\n",
      "\n",
      "1    885\n",
      "2    663\n",
      "0     32\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 46: (RobustScaler(), MLPClassifier(hidden_layer_sizes=(20, 10))) - Profit Sum: -73433.79534220044 - Profit ratio: -0.46477085659620526\n",
      "Classification Report for Combination 46:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.31      0.30       401\n",
      "           1       0.56      0.54      0.55       690\n",
      "           2       0.45      0.45      0.45       489\n",
      "\n",
      "    accuracy                           0.46      1580\n",
      "   macro avg       0.44      0.44      0.44      1580\n",
      "weighted avg       0.46      0.46      0.46      1580\n",
      "\n",
      "\n",
      "1    663\n",
      "2    490\n",
      "0    427\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 47: (RobustScaler(), MLPClassifier(hidden_layer_sizes=(50, 25), learning_rate_init=0.0001)) - Profit Sum: -85719.19691020236 - Profit ratio: -0.5425265627227998\n",
      "Classification Report for Combination 47:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.17      0.22       401\n",
      "           1       0.58      0.65      0.61       690\n",
      "           2       0.44      0.53      0.48       489\n",
      "\n",
      "    accuracy                           0.49      1580\n",
      "   macro avg       0.44      0.45      0.44      1580\n",
      "weighted avg       0.47      0.49      0.47      1580\n",
      "\n",
      "\n",
      "1    775\n",
      "2    580\n",
      "0    225\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 48: (RobustScaler(), RandomForestClassifier(max_depth=10, n_estimators=500)) - Profit Sum: -95765.59043621893 - Profit ratio: -0.6061113318748034\n",
      "Classification Report for Combination 48:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.06      0.10       401\n",
      "           1       0.56      0.76      0.64       690\n",
      "           2       0.47      0.54      0.50       489\n",
      "\n",
      "    accuracy                           0.51      1580\n",
      "   macro avg       0.44      0.45      0.42      1580\n",
      "weighted avg       0.47      0.51      0.46      1580\n",
      "\n",
      "\n",
      "1    944\n",
      "2    553\n",
      "0     83\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 49: (RobustScaler(), RandomForestClassifier(max_depth=20, n_estimators=1000)) - Profit Sum: -88226.6199082812 - Profit ratio: -0.5583963285334252\n",
      "Classification Report for Combination 49:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.15      0.20       401\n",
      "           1       0.57      0.66      0.61       690\n",
      "           2       0.46      0.52      0.49       489\n",
      "\n",
      "    accuracy                           0.49      1580\n",
      "   macro avg       0.43      0.45      0.43      1580\n",
      "weighted avg       0.46      0.49      0.47      1580\n",
      "\n",
      "\n",
      "1    802\n",
      "2    556\n",
      "0    222\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 50: (RobustScaler(), AdaBoostClassifier(learning_rate=0.01, n_estimators=100)) - Profit Sum: -100986.77746833453 - Profit ratio: -0.6391568194198388\n",
      "Classification Report for Combination 50:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       401\n",
      "           1       0.53      0.80      0.64       690\n",
      "           2       0.48      0.52      0.50       489\n",
      "\n",
      "    accuracy                           0.51      1580\n",
      "   macro avg       0.34      0.44      0.38      1580\n",
      "weighted avg       0.38      0.51      0.43      1580\n",
      "\n",
      "\n",
      "1    1051\n",
      "2     529\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 51: (RobustScaler(), AdaBoostClassifier(learning_rate=0.1, n_estimators=500)) - Profit Sum: -98030.55986765533 - Profit ratio: -0.6204465814408565\n",
      "Classification Report for Combination 51:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.06      0.10       401\n",
      "           1       0.56      0.75      0.64       690\n",
      "           2       0.47      0.55      0.51       489\n",
      "\n",
      "    accuracy                           0.51      1580\n",
      "   macro avg       0.44      0.45      0.42      1580\n",
      "weighted avg       0.46      0.51      0.46      1580\n",
      "\n",
      "\n",
      "1    917\n",
      "2    577\n",
      "0     86\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 52: (RobustScaler(), KNeighborsClassifier()) - Profit Sum: -64594.465539864585 - Profit ratio: -0.40882573126496574\n",
      "Classification Report for Combination 52:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.36      0.31       401\n",
      "           1       0.53      0.52      0.52       690\n",
      "           2       0.47      0.35      0.40       489\n",
      "\n",
      "    accuracy                           0.43      1580\n",
      "   macro avg       0.42      0.41      0.41      1580\n",
      "weighted avg       0.44      0.43      0.43      1580\n",
      "\n",
      "\n",
      "1    681\n",
      "0    536\n",
      "2    363\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 53: (RobustScaler(), KNeighborsClassifier(n_neighbors=7)) - Profit Sum: -66406.93908825156 - Profit ratio: -0.42029708283703515\n",
      "Classification Report for Combination 53:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.32      0.30       401\n",
      "           1       0.54      0.54      0.54       690\n",
      "           2       0.45      0.39      0.42       489\n",
      "\n",
      "    accuracy                           0.44      1580\n",
      "   macro avg       0.42      0.42      0.42      1580\n",
      "weighted avg       0.45      0.44      0.44      1580\n",
      "\n",
      "\n",
      "1    693\n",
      "0    461\n",
      "2    426\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 54: (RobustScaler(), GaussianNB(var_smoothing=0.1)) - Profit Sum: -87241.9449370598 - Profit ratio: -0.5521642084624038\n",
      "Classification Report for Combination 54:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       401\n",
      "           1       0.48      0.95      0.64       690\n",
      "           2       0.61      0.27      0.38       489\n",
      "\n",
      "    accuracy                           0.50      1580\n",
      "   macro avg       0.36      0.41      0.34      1580\n",
      "weighted avg       0.40      0.50      0.40      1580\n",
      "\n",
      "\n",
      "1    1363\n",
      "2     217\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 55: (RobustScaler(), GaussianNB(var_smoothing=0.01)) - Profit Sum: -67029.6524902852 - Profit ratio: -0.4242383069005392\n",
      "Classification Report for Combination 55:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.41      0.35       401\n",
      "           1       0.66      0.48      0.55       690\n",
      "           2       0.49      0.53      0.51       489\n",
      "\n",
      "    accuracy                           0.48      1580\n",
      "   macro avg       0.48      0.47      0.47      1580\n",
      "weighted avg       0.52      0.48      0.49      1580\n",
      "\n",
      "\n",
      "0    555\n",
      "2    526\n",
      "1    499\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 56: (RobustScaler(), LogisticRegression(C=0.1)) - Profit Sum: -95208.32629462903 - Profit ratio: -0.6025843436368926\n",
      "Classification Report for Combination 56:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.10      0.16       401\n",
      "           1       0.58      0.70      0.63       690\n",
      "           2       0.47      0.60      0.53       489\n",
      "\n",
      "    accuracy                           0.52      1580\n",
      "   macro avg       0.46      0.47      0.44      1580\n",
      "weighted avg       0.48      0.52      0.48      1580\n",
      "\n",
      "\n",
      "1    834\n",
      "2    618\n",
      "0    128\n",
      "Name: y_prediction, dtype: int64\n",
      "Combination 57: (RobustScaler(), LogisticRegression(C=0.01)) - Profit Sum: -96041.22374398955 - Profit ratio: -0.6078558464809466\n",
      "Classification Report for Combination 57:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.08      0.13       401\n",
      "           1       0.58      0.72      0.64       690\n",
      "           2       0.48      0.61      0.53       489\n",
      "\n",
      "    accuracy                           0.52      1580\n",
      "   macro avg       0.47      0.47      0.43      1580\n",
      "weighted avg       0.49      0.52      0.48      1580\n",
      "\n",
      "\n",
      "1    865\n",
      "2    623\n",
      "0     92\n",
      "Name: y_prediction, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "profit_sums_b,classification_reports_b = train_model_102(step10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcca105f",
   "metadata": {},
   "source": [
    "#  MODEL C: 1-0-2  - by Score Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b559e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_win_lose(df):\n",
    "    \n",
    "    #copy the df just in case\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    #Drop unnecessary columns\n",
    "    df_processed.drop(['League', 'team1', 'team2','point_team1', 'point_team2','spi_1','spi_2'], axis=1, inplace=True)\n",
    "    df_processed.loc[df_processed['scor_diff'] == 9, 'scor_diff'] = 8\n",
    "    df_processed.loc[df_processed['scor_diff'] == -9, 'scor_diff'] = -8\n",
    "    \n",
    "    #Define feature and target columns\n",
    "    X = df_processed.drop(['scor_diff'], axis=1)\n",
    "    y = df_processed['scor_diff']\n",
    "\n",
    "    # Sort the DataFrame by date columns in descending order\n",
    "    df_sorted = df_processed.sort_values(by=['Year', 'Month', 'Week_ofday'], ascending=True)\n",
    "    \n",
    "    # Calculate the indices for the train-test split\n",
    "    train_size = int(0.75 * len(df_sorted))\n",
    "    train_indices = df_sorted.index[:train_size]\n",
    "    test_indices = df_sorted.index[train_size:]\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train = X.loc[train_indices]\n",
    "    X_test = X.loc[test_indices]\n",
    "    y_train = y.loc[train_indices]\n",
    "    y_test = y.loc[test_indices]\n",
    "  \n",
    "    # Create a list of all possible combinations of hyperparameters\n",
    "    scaling = [MinMaxScaler(), StandardScaler(),RobustScaler()]\n",
    "    classifier = [\n",
    "        KNeighborsClassifier(3),\n",
    "        DecisionTreeClassifier(max_depth=5),\n",
    "        GaussianNB(),\n",
    "        RandomForestClassifier(max_depth=5, n_estimators=300),\n",
    "        AdaBoostClassifier(learning_rate=0.1),\n",
    "        LogisticRegression(),\n",
    "        MLPClassifier(hidden_layer_sizes=(10, 5), learning_rate_init=0.01),\n",
    "        MLPClassifier(hidden_layer_sizes=(20, 10), learning_rate_init=0.001),\n",
    "        MLPClassifier(hidden_layer_sizes=(50, 25), learning_rate_init=0.0001),\n",
    "        RandomForestClassifier(max_depth=10, n_estimators=500),\n",
    "        RandomForestClassifier(max_depth=20, n_estimators=1000),\n",
    "        AdaBoostClassifier(learning_rate=0.01, n_estimators=100),\n",
    "        AdaBoostClassifier(learning_rate=0.1, n_estimators=500),\n",
    "        KNeighborsClassifier(5),\n",
    "        KNeighborsClassifier(7),\n",
    "        GaussianNB(var_smoothing=0.1),\n",
    "        GaussianNB(var_smoothing=0.01),\n",
    "        LogisticRegression(C=0.1),\n",
    "        LogisticRegression(C=0.01)\n",
    "    ]\n",
    "     \n",
    "    #Save the combination of scalers and classifiers\n",
    "    combinations = list(itertools.product( scaling, classifier))\n",
    "    \n",
    "    # Initialize empty lists to store sums of profit and classification reports\n",
    "    profit_sums = []\n",
    "    classification_reports = []\n",
    "     \n",
    "    #Put the pipeline in  for loop to see all the profits made by all combination\n",
    "    for i, combo in enumerate(combinations):\n",
    "        # Create a pipeline\n",
    "        pipe = Pipeline([\n",
    "            ('scaling', combo[0]),\n",
    "            ('classifier', combo[1])\n",
    "        ])\n",
    "\n",
    "        # Fit the model\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions on test set\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        \n",
    "        # Calculate classification report\n",
    "        clas_report = classification_report(y_test, y_pred)\n",
    "        classification_reports.append(clas_report)\n",
    "        \n",
    "        df_result = df.loc[y_test.index].copy()\n",
    "        df_result['y_prediction'] = y_pred\n",
    "\n",
    "        df_result_step2 = df_result.copy()\n",
    "        \n",
    "        df_result_step2['True_False'] = 0  # Initialize with 0 (incorrect prediction)\n",
    "    \n",
    "        ###############################    \n",
    "        # LOST BET\n",
    "        df_result_step2.loc[((df_result_step2['scor_diff'] < 0) & (df_result_step2['y_prediction'] >= 0)) |\n",
    "                        ((df_result_step2['scor_diff'] > 0) & (df_result_step2['y_prediction'] <= 0)) |\n",
    "                        ((df_result_step2['scor_diff'] == 0) & (df_result_step2['y_prediction'] != 0)), 'True_False'] = 0\n",
    "    \n",
    "        # WON BET\n",
    "        df_result_step2.loc[((df_result_step2['scor_diff'] < 0) & (df_result_step2['y_prediction'] < 0)) |\n",
    "                        ((df_result_step2['scor_diff'] > 0) & (df_result_step2['y_prediction'] > 0)) |\n",
    "                        ((df_result_step2['scor_diff'] == 0) & (df_result_step2['y_prediction'] == 0)), 'True_False'] = 1\n",
    "    \n",
    "        df_result_step2['True_False'] = df_result_step2['True_False'].astype(int)\n",
    "        ###############################\n",
    "        df_result_step2 = probability_to_reg_dnb_odds(df_result_step2)\n",
    "        df_result_step2['profit'] = df_result_step2.apply(calculate_value_dnb, axis=1)\n",
    "\n",
    "        # Calculate the sum of 'profit' column\n",
    "        profit_sum = df_result_step2['profit'].sum()\n",
    "        profit_sums.append(profit_sum)\n",
    "        \n",
    "        #Print the metrics\n",
    "        print(f\"Combination {i+1}: {combo} - Profit Sum: {profit_sum} - Profit ratio: {profit_sum/(len(df_result_step2)*100)}\")\n",
    "        print(f\"Classification Report for Combination {i+1}:\\n{clas_report}\\n\")\n",
    "        print(df_result_step2.True_False.value_counts())\n",
    "        print(df_result_step2.True_False.value_counts()[0])\n",
    "        print(df_result_step2.True_False.value_counts()[1])\n",
    "\n",
    "    return profit_sums, classification_reports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "641eefc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 1: (MinMaxScaler(), KNeighborsClassifier(n_neighbors=3)) - Profit Sum: -61515.46100325977 - Profit ratio: -0.3893383607801251\n",
      "Classification Report for Combination 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.02      0.05      0.03        19\n",
      "          -3       0.10      0.19      0.13        68\n",
      "          -2       0.06      0.14      0.09       116\n",
      "          -1       0.19      0.28      0.23       274\n",
      "           0       0.28      0.32      0.30       401\n",
      "           1       0.25      0.11      0.16       348\n",
      "           2       0.21      0.09      0.13       174\n",
      "           3       0.11      0.03      0.05        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.19      1580\n",
      "   macro avg       0.08      0.08      0.07      1580\n",
      "weighted avg       0.20      0.19      0.18      1580\n",
      "\n",
      "\n",
      "0    979\n",
      "1    601\n",
      "Name: True_False, dtype: int64\n",
      "979\n",
      "601\n",
      "Combination 2: (MinMaxScaler(), DecisionTreeClassifier(max_depth=5)) - Profit Sum: -87356.48472023863 - Profit ratio: -0.5528891437989787\n",
      "Classification Report for Combination 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.09      0.02      0.03       116\n",
      "          -1       0.25      0.31      0.28       274\n",
      "           0       0.26      0.65      0.37       401\n",
      "           1       0.28      0.09      0.13       348\n",
      "           2       0.17      0.10      0.12       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.07      0.08      0.06      1580\n",
      "weighted avg       0.20      0.25      0.19      1580\n",
      "\n",
      "\n",
      "0    990\n",
      "1    590\n",
      "Name: True_False, dtype: int64\n",
      "990\n",
      "590\n",
      "Combination 3: (MinMaxScaler(), GaussianNB()) - Profit Sum: -70174.94093232686 - Profit ratio: -0.4441451957742206\n",
      "Classification Report for Combination 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.03      0.14      0.05         7\n",
      "          -4       0.04      0.16      0.06        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.10      0.09      0.10       116\n",
      "          -1       0.22      0.18      0.20       274\n",
      "           0       0.28      0.54      0.37       401\n",
      "           1       0.27      0.05      0.08       348\n",
      "           2       0.24      0.13      0.17       174\n",
      "           3       0.16      0.11      0.14        87\n",
      "           4       0.11      0.03      0.05        68\n",
      "           5       0.04      0.20      0.06        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.21      1580\n",
      "   macro avg       0.09      0.10      0.08      1580\n",
      "weighted avg       0.22      0.21      0.18      1580\n",
      "\n",
      "\n",
      "0    882\n",
      "1    698\n",
      "Name: True_False, dtype: int64\n",
      "882\n",
      "698\n",
      "Combination 4: (MinMaxScaler(), RandomForestClassifier(max_depth=5, n_estimators=300)) - Profit Sum: -94166.35265401685 - Profit ratio: -0.5959895737596004\n",
      "Classification Report for Combination 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.06      0.01      0.02       116\n",
      "          -1       0.25      0.18      0.21       274\n",
      "           0       0.27      0.79      0.40       401\n",
      "           1       0.32      0.10      0.16       348\n",
      "           2       0.15      0.07      0.09       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      1580\n",
      "   macro avg       0.07      0.08      0.06      1580\n",
      "weighted avg       0.20      0.26      0.18      1580\n",
      "\n",
      "\n",
      "0    1001\n",
      "1     579\n",
      "Name: True_False, dtype: int64\n",
      "1001\n",
      "579\n",
      "Combination 5: (MinMaxScaler(), AdaBoostClassifier(learning_rate=0.1)) - Profit Sum: -101535.80176127196 - Profit ratio: -0.6426316567169111\n",
      "Classification Report for Combination 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.31      0.07      0.11       274\n",
      "           0       0.27      0.87      0.41       401\n",
      "           1       0.30      0.16      0.21       348\n",
      "           2       0.06      0.01      0.01       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.27      1580\n",
      "   macro avg       0.06      0.07      0.05      1580\n",
      "weighted avg       0.19      0.27      0.17      1580\n",
      "\n",
      "\n",
      "0    1048\n",
      "1     532\n",
      "Name: True_False, dtype: int64\n",
      "1048\n",
      "532\n",
      "Combination 6: (MinMaxScaler(), LogisticRegression()) - Profit Sum: -96552.6442336214 - Profit ratio: -0.6110926850229202\n",
      "Classification Report for Combination 6:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.07      0.03      0.05       116\n",
      "          -1       0.20      0.09      0.13       274\n",
      "           0       0.27      0.83      0.41       401\n",
      "           1       0.29      0.08      0.13       348\n",
      "           2       0.17      0.07      0.10       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.07      0.07      0.05      1580\n",
      "weighted avg       0.19      0.25      0.17      1580\n",
      "\n",
      "\n",
      "0    1018\n",
      "1     562\n",
      "Name: True_False, dtype: int64\n",
      "1018\n",
      "562\n",
      "Combination 7: (MinMaxScaler(), MLPClassifier(hidden_layer_sizes=(10, 5), learning_rate_init=0.01)) - Profit Sum: -75329.06178900436 - Profit ratio: -0.476766213854458\n",
      "Classification Report for Combination 7:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.10      0.02      0.03       116\n",
      "          -1       0.24      0.27      0.25       274\n",
      "           0       0.28      0.58      0.38       401\n",
      "           1       0.29      0.30      0.30       348\n",
      "           2       0.12      0.05      0.07       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      1580\n",
      "   macro avg       0.07      0.08      0.07      1580\n",
      "weighted avg       0.20      0.26      0.21      1580\n",
      "\n",
      "\n",
      "0    890\n",
      "1    690\n",
      "Name: True_False, dtype: int64\n",
      "890\n",
      "690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 8: (MinMaxScaler(), MLPClassifier(hidden_layer_sizes=(20, 10))) - Profit Sum: -89270.65275434178 - Profit ratio: -0.5650041313565936\n",
      "Classification Report for Combination 8:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.06      0.02      0.03       116\n",
      "          -1       0.25      0.18      0.21       274\n",
      "           0       0.27      0.74      0.40       401\n",
      "           1       0.28      0.14      0.18       348\n",
      "           2       0.22      0.11      0.15       174\n",
      "           3       0.29      0.02      0.04        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      1580\n",
      "   macro avg       0.09      0.08      0.07      1580\n",
      "weighted avg       0.22      0.26      0.20      1580\n",
      "\n",
      "\n",
      "0    973\n",
      "1    607\n",
      "Name: True_False, dtype: int64\n",
      "973\n",
      "607\n",
      "Combination 9: (MinMaxScaler(), MLPClassifier(hidden_layer_sizes=(50, 25), learning_rate_init=0.0001)) - Profit Sum: -94906.90483588958 - Profit ratio: -0.6006766128853771\n",
      "Classification Report for Combination 9:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.26      0.15      0.19       274\n",
      "           0       0.27      0.82      0.41       401\n",
      "           1       0.27      0.08      0.12       348\n",
      "           2       0.14      0.06      0.09       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      1580\n",
      "   macro avg       0.06      0.07      0.05      1580\n",
      "weighted avg       0.19      0.26      0.17      1580\n",
      "\n",
      "\n",
      "0    1007\n",
      "1     573\n",
      "Name: True_False, dtype: int64\n",
      "1007\n",
      "573\n",
      "Combination 10: (MinMaxScaler(), RandomForestClassifier(max_depth=10, n_estimators=500)) - Profit Sum: -91722.76205896874 - Profit ratio: -0.5805238104998022\n",
      "Classification Report for Combination 10:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.06      0.02      0.03       116\n",
      "          -1       0.26      0.19      0.22       274\n",
      "           0       0.26      0.73      0.39       401\n",
      "           1       0.29      0.11      0.16       348\n",
      "           2       0.20      0.09      0.13       174\n",
      "           3       0.09      0.01      0.02        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.08      0.08      0.06      1580\n",
      "weighted avg       0.21      0.25      0.19      1580\n",
      "\n",
      "\n",
      "0    1002\n",
      "1     578\n",
      "Name: True_False, dtype: int64\n",
      "1002\n",
      "578\n",
      "Combination 11: (MinMaxScaler(), RandomForestClassifier(max_depth=20, n_estimators=1000)) - Profit Sum: -82434.94636853295 - Profit ratio: -0.521740166889449\n",
      "Classification Report for Combination 11:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.50      0.05      0.10        19\n",
      "          -3       0.25      0.01      0.03        68\n",
      "          -2       0.09      0.04      0.06       116\n",
      "          -1       0.23      0.20      0.21       274\n",
      "           0       0.26      0.59      0.36       401\n",
      "           1       0.26      0.17      0.21       348\n",
      "           2       0.18      0.11      0.14       174\n",
      "           3       0.09      0.02      0.04        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.24      1580\n",
      "   macro avg       0.12      0.08      0.08      1580\n",
      "weighted avg       0.21      0.24      0.20      1580\n",
      "\n",
      "\n",
      "0    982\n",
      "1    598\n",
      "Name: True_False, dtype: int64\n",
      "982\n",
      "598\n",
      "Combination 12: (MinMaxScaler(), AdaBoostClassifier(learning_rate=0.01, n_estimators=100)) - Profit Sum: -117900.0 - Profit ratio: -0.7462025316455696\n",
      "Classification Report for Combination 12:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.00      0.00      0.00       274\n",
      "           0       0.25      1.00      0.40       401\n",
      "           1       0.00      0.00      0.00       348\n",
      "           2       0.00      0.00      0.00       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.02      0.07      0.03      1580\n",
      "weighted avg       0.06      0.25      0.10      1580\n",
      "\n",
      "\n",
      "0    1179\n",
      "1     401\n",
      "Name: True_False, dtype: int64\n",
      "1179\n",
      "401\n",
      "Combination 13: (MinMaxScaler(), AdaBoostClassifier(learning_rate=0.1, n_estimators=500)) - Profit Sum: -86981.92792325743 - Profit ratio: -0.5505185311598572\n",
      "Classification Report for Combination 13:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.23      0.18      0.20       274\n",
      "           0       0.27      0.69      0.39       401\n",
      "           1       0.23      0.04      0.06       348\n",
      "           2       0.16      0.14      0.15       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.12      0.01      0.03        68\n",
      "           5       0.07      0.30      0.11        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.23      1580\n",
      "   macro avg       0.07      0.08      0.06      1580\n",
      "weighted avg       0.18      0.23      0.17      1580\n",
      "\n",
      "\n",
      "0    961\n",
      "1    619\n",
      "Name: True_False, dtype: int64\n",
      "961\n",
      "619\n",
      "Combination 14: (MinMaxScaler(), KNeighborsClassifier()) - Profit Sum: -67328.3250786434 - Profit ratio: -0.4261286397382493\n",
      "Classification Report for Combination 14:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.05      0.04      0.05        68\n",
      "          -2       0.08      0.09      0.09       116\n",
      "          -1       0.20      0.29      0.24       274\n",
      "           0       0.28      0.38      0.32       401\n",
      "           1       0.26      0.19      0.22       348\n",
      "           2       0.16      0.11      0.13       174\n",
      "           3       0.08      0.03      0.05        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.21      1580\n",
      "   macro avg       0.07      0.08      0.07      1580\n",
      "weighted avg       0.19      0.21      0.20      1580\n",
      "\n",
      "\n",
      "0    969\n",
      "1    611\n",
      "Name: True_False, dtype: int64\n",
      "969\n",
      "611\n",
      "Combination 15: (MinMaxScaler(), KNeighborsClassifier(n_neighbors=7)) - Profit Sum: -66513.73970309155 - Profit ratio: -0.4209730360955161\n",
      "Classification Report for Combination 15:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.02      0.01      0.02        68\n",
      "          -2       0.12      0.12      0.12       116\n",
      "          -1       0.20      0.28      0.23       274\n",
      "           0       0.28      0.41      0.33       401\n",
      "           1       0.23      0.18      0.20       348\n",
      "           2       0.18      0.13      0.15       174\n",
      "           3       0.12      0.03      0.05        87\n",
      "           4       0.17      0.01      0.03        68\n",
      "           5       0.25      0.10      0.14        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.22      1580\n",
      "   macro avg       0.10      0.09      0.09      1580\n",
      "weighted avg       0.20      0.22      0.20      1580\n",
      "\n",
      "\n",
      "0    946\n",
      "1    634\n",
      "Name: True_False, dtype: int64\n",
      "946\n",
      "634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 16: (MinMaxScaler(), GaussianNB(var_smoothing=0.1)) - Profit Sum: -76653.12565264906 - Profit ratio: -0.4851463648901839\n",
      "Classification Report for Combination 16:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.04      0.11      0.05        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.14      0.09      0.11       116\n",
      "          -1       0.21      0.15      0.18       274\n",
      "           0       0.27      0.60      0.38       401\n",
      "           1       0.19      0.03      0.05       348\n",
      "           2       0.23      0.14      0.17       174\n",
      "           3       0.17      0.05      0.07        87\n",
      "           4       0.14      0.01      0.03        68\n",
      "           5       0.05      0.20      0.08        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.21      1580\n",
      "   macro avg       0.09      0.09      0.07      1580\n",
      "weighted avg       0.20      0.21      0.17      1580\n",
      "\n",
      "\n",
      "0    917\n",
      "1    663\n",
      "Name: True_False, dtype: int64\n",
      "917\n",
      "663\n",
      "Combination 17: (MinMaxScaler(), GaussianNB(var_smoothing=0.01)) - Profit Sum: -70555.45253032222 - Profit ratio: -0.4465534970273558\n",
      "Classification Report for Combination 17:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.03      0.14      0.05         7\n",
      "          -4       0.04      0.16      0.06        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.10      0.09      0.09       116\n",
      "          -1       0.23      0.18      0.20       274\n",
      "           0       0.28      0.54      0.37       401\n",
      "           1       0.25      0.04      0.07       348\n",
      "           2       0.23      0.13      0.16       174\n",
      "           3       0.17      0.10      0.13        87\n",
      "           4       0.13      0.03      0.05        68\n",
      "           5       0.04      0.20      0.07        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.21      1580\n",
      "   macro avg       0.09      0.10      0.08      1580\n",
      "weighted avg       0.21      0.21      0.18      1580\n",
      "\n",
      "\n",
      "0    884\n",
      "1    696\n",
      "Name: True_False, dtype: int64\n",
      "884\n",
      "696\n",
      "Combination 18: (MinMaxScaler(), LogisticRegression(C=0.1)) - Profit Sum: -100183.38871100855 - Profit ratio: -0.6340720804494212\n",
      "Classification Report for Combination 18:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.07      0.02      0.03       116\n",
      "          -1       0.24      0.09      0.13       274\n",
      "           0       0.27      0.87      0.41       401\n",
      "           1       0.27      0.06      0.10       348\n",
      "           2       0.20      0.07      0.11       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      1580\n",
      "   macro avg       0.07      0.07      0.05      1580\n",
      "weighted avg       0.20      0.26      0.16      1580\n",
      "\n",
      "\n",
      "0    1039\n",
      "1     541\n",
      "Name: True_False, dtype: int64\n",
      "1039\n",
      "541\n",
      "Combination 19: (MinMaxScaler(), LogisticRegression(C=0.01)) - Profit Sum: -110601.44740500794 - Profit ratio: -0.7000091607911895\n",
      "Classification Report for Combination 19:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.27      0.05      0.08       274\n",
      "           0       0.26      0.94      0.40       401\n",
      "           1       0.27      0.04      0.07       348\n",
      "           2       0.21      0.02      0.04       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      1580\n",
      "   macro avg       0.07      0.07      0.04      1580\n",
      "weighted avg       0.19      0.26      0.14      1580\n",
      "\n",
      "\n",
      "0    1117\n",
      "1     463\n",
      "Name: True_False, dtype: int64\n",
      "1117\n",
      "463\n",
      "Combination 20: (StandardScaler(), KNeighborsClassifier(n_neighbors=3)) - Profit Sum: -60231.158869070925 - Profit ratio: -0.3812098662599426\n",
      "Classification Report for Combination 20:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.05      0.11      0.06        19\n",
      "          -3       0.09      0.19      0.12        68\n",
      "          -2       0.08      0.18      0.11       116\n",
      "          -1       0.19      0.27      0.22       274\n",
      "           0       0.26      0.30      0.28       401\n",
      "           1       0.25      0.13      0.17       348\n",
      "           2       0.18      0.06      0.09       174\n",
      "           3       0.14      0.03      0.06        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.18      1580\n",
      "   macro avg       0.08      0.09      0.07      1580\n",
      "weighted avg       0.19      0.18      0.18      1580\n",
      "\n",
      "\n",
      "0    984\n",
      "1    596\n",
      "Name: True_False, dtype: int64\n",
      "984\n",
      "596\n",
      "Combination 21: (StandardScaler(), DecisionTreeClassifier(max_depth=5)) - Profit Sum: -87356.48472023863 - Profit ratio: -0.5528891437989787\n",
      "Classification Report for Combination 21:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.09      0.02      0.03       116\n",
      "          -1       0.25      0.31      0.28       274\n",
      "           0       0.26      0.65      0.37       401\n",
      "           1       0.28      0.09      0.13       348\n",
      "           2       0.17      0.10      0.12       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.07      0.08      0.06      1580\n",
      "weighted avg       0.20      0.25      0.19      1580\n",
      "\n",
      "\n",
      "0    990\n",
      "1    590\n",
      "Name: True_False, dtype: int64\n",
      "990\n",
      "590\n",
      "Combination 22: (StandardScaler(), GaussianNB()) - Profit Sum: -70174.94093232686 - Profit ratio: -0.4441451957742206\n",
      "Classification Report for Combination 22:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.03      0.14      0.05         7\n",
      "          -4       0.04      0.16      0.06        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.10      0.09      0.10       116\n",
      "          -1       0.22      0.18      0.20       274\n",
      "           0       0.28      0.54      0.37       401\n",
      "           1       0.27      0.05      0.08       348\n",
      "           2       0.24      0.13      0.17       174\n",
      "           3       0.16      0.11      0.14        87\n",
      "           4       0.11      0.03      0.05        68\n",
      "           5       0.04      0.20      0.06        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.21      1580\n",
      "   macro avg       0.09      0.10      0.08      1580\n",
      "weighted avg       0.22      0.21      0.18      1580\n",
      "\n",
      "\n",
      "0    882\n",
      "1    698\n",
      "Name: True_False, dtype: int64\n",
      "882\n",
      "698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 23: (StandardScaler(), RandomForestClassifier(max_depth=5, n_estimators=300)) - Profit Sum: -94450.231022706 - Profit ratio: -0.5977862722956075\n",
      "Classification Report for Combination 23:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.06      0.01      0.02       116\n",
      "          -1       0.23      0.16      0.19       274\n",
      "           0       0.27      0.79      0.40       401\n",
      "           1       0.33      0.10      0.15       348\n",
      "           2       0.12      0.06      0.08       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      1580\n",
      "   macro avg       0.07      0.07      0.06      1580\n",
      "weighted avg       0.20      0.26      0.18      1580\n",
      "\n",
      "\n",
      "0    1003\n",
      "1     577\n",
      "Name: True_False, dtype: int64\n",
      "1003\n",
      "577\n",
      "Combination 24: (StandardScaler(), AdaBoostClassifier(learning_rate=0.1)) - Profit Sum: -101535.80176127196 - Profit ratio: -0.6426316567169111\n",
      "Classification Report for Combination 24:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.31      0.07      0.11       274\n",
      "           0       0.27      0.87      0.41       401\n",
      "           1       0.30      0.16      0.21       348\n",
      "           2       0.06      0.01      0.01       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.27      1580\n",
      "   macro avg       0.06      0.07      0.05      1580\n",
      "weighted avg       0.19      0.27      0.17      1580\n",
      "\n",
      "\n",
      "0    1048\n",
      "1     532\n",
      "Name: True_False, dtype: int64\n",
      "1048\n",
      "532\n",
      "Combination 25: (StandardScaler(), LogisticRegression()) - Profit Sum: -95237.06656770754 - Profit ratio: -0.6027662440994148\n",
      "Classification Report for Combination 25:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.08      0.04      0.06       116\n",
      "          -1       0.20      0.09      0.12       274\n",
      "           0       0.27      0.82      0.41       401\n",
      "           1       0.28      0.08      0.12       348\n",
      "           2       0.17      0.08      0.11       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.07      0.07      0.05      1580\n",
      "weighted avg       0.19      0.25      0.17      1580\n",
      "\n",
      "\n",
      "0    1010\n",
      "1     570\n",
      "Name: True_False, dtype: int64\n",
      "1010\n",
      "570\n",
      "Combination 26: (StandardScaler(), MLPClassifier(hidden_layer_sizes=(10, 5), learning_rate_init=0.01)) - Profit Sum: -85585.06508679879 - Profit ratio: -0.5416776271316379\n",
      "Classification Report for Combination 26:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.18      0.07      0.10       116\n",
      "          -1       0.23      0.14      0.17       274\n",
      "           0       0.27      0.71      0.39       401\n",
      "           1       0.28      0.11      0.16       348\n",
      "           2       0.17      0.19      0.18       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.08      0.08      0.07      1580\n",
      "weighted avg       0.20      0.25      0.19      1580\n",
      "\n",
      "\n",
      "0    956\n",
      "1    624\n",
      "Name: True_False, dtype: int64\n",
      "956\n",
      "624\n",
      "Combination 27: (StandardScaler(), MLPClassifier(hidden_layer_sizes=(20, 10))) - Profit Sum: -87130.11041987414 - Profit ratio: -0.5514563950624946\n",
      "Classification Report for Combination 27:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.18      0.04      0.07       116\n",
      "          -1       0.25      0.22      0.23       274\n",
      "           0       0.27      0.70      0.39       401\n",
      "           1       0.26      0.14      0.19       348\n",
      "           2       0.16      0.06      0.09       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      1580\n",
      "   macro avg       0.07      0.08      0.06      1580\n",
      "weighted avg       0.20      0.26      0.19      1580\n",
      "\n",
      "\n",
      "0    994\n",
      "1    586\n",
      "Name: True_False, dtype: int64\n",
      "994\n",
      "586\n",
      "Combination 28: (StandardScaler(), MLPClassifier(hidden_layer_sizes=(50, 25), learning_rate_init=0.0001)) - Profit Sum: -95011.297065431 - Profit ratio: -0.6013373231989304\n",
      "Classification Report for Combination 28:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.10      0.02      0.03       116\n",
      "          -1       0.24      0.17      0.20       274\n",
      "           0       0.26      0.74      0.38       401\n",
      "           1       0.24      0.08      0.12       348\n",
      "           2       0.16      0.09      0.11       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.07      0.07      0.06      1580\n",
      "weighted avg       0.18      0.25      0.17      1580\n",
      "\n",
      "\n",
      "0    1027\n",
      "1     553\n",
      "Name: True_False, dtype: int64\n",
      "1027\n",
      "553\n",
      "Combination 29: (StandardScaler(), RandomForestClassifier(max_depth=10, n_estimators=500)) - Profit Sum: -91688.3877315149 - Profit ratio: -0.5803062514652841\n",
      "Classification Report for Combination 29:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.05      0.02      0.03       116\n",
      "          -1       0.26      0.18      0.21       274\n",
      "           0       0.26      0.73      0.38       401\n",
      "           1       0.28      0.11      0.16       348\n",
      "           2       0.18      0.08      0.11       174\n",
      "           3       0.09      0.01      0.02        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.07      0.07      0.06      1580\n",
      "weighted avg       0.20      0.25      0.18      1580\n",
      "\n",
      "\n",
      "0    1003\n",
      "1     577\n",
      "Name: True_False, dtype: int64\n",
      "1003\n",
      "577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 30: (StandardScaler(), RandomForestClassifier(max_depth=20, n_estimators=1000)) - Profit Sum: -84226.28125494573 - Profit ratio: -0.5330777294616819\n",
      "Classification Report for Combination 30:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.17      0.01      0.03        68\n",
      "          -2       0.08      0.03      0.05       116\n",
      "          -1       0.24      0.21      0.22       274\n",
      "           0       0.25      0.59      0.36       401\n",
      "           1       0.25      0.16      0.20       348\n",
      "           2       0.19      0.10      0.13       174\n",
      "           3       0.10      0.02      0.04        87\n",
      "           4       0.20      0.01      0.03        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.24      1580\n",
      "   macro avg       0.10      0.08      0.07      1580\n",
      "weighted avg       0.21      0.24      0.20      1580\n",
      "\n",
      "\n",
      "0    992\n",
      "1    588\n",
      "Name: True_False, dtype: int64\n",
      "992\n",
      "588\n",
      "Combination 31: (StandardScaler(), AdaBoostClassifier(learning_rate=0.01, n_estimators=100)) - Profit Sum: -117900.0 - Profit ratio: -0.7462025316455696\n",
      "Classification Report for Combination 31:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.00      0.00      0.00       274\n",
      "           0       0.25      1.00      0.40       401\n",
      "           1       0.00      0.00      0.00       348\n",
      "           2       0.00      0.00      0.00       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.02      0.07      0.03      1580\n",
      "weighted avg       0.06      0.25      0.10      1580\n",
      "\n",
      "\n",
      "0    1179\n",
      "1     401\n",
      "Name: True_False, dtype: int64\n",
      "1179\n",
      "401\n",
      "Combination 32: (StandardScaler(), AdaBoostClassifier(learning_rate=0.1, n_estimators=500)) - Profit Sum: -86981.92792325743 - Profit ratio: -0.5505185311598572\n",
      "Classification Report for Combination 32:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.23      0.18      0.20       274\n",
      "           0       0.27      0.69      0.39       401\n",
      "           1       0.23      0.04      0.06       348\n",
      "           2       0.16      0.14      0.15       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.12      0.01      0.03        68\n",
      "           5       0.07      0.30      0.11        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.23      1580\n",
      "   macro avg       0.07      0.08      0.06      1580\n",
      "weighted avg       0.18      0.23      0.17      1580\n",
      "\n",
      "\n",
      "0    961\n",
      "1    619\n",
      "Name: True_False, dtype: int64\n",
      "961\n",
      "619\n",
      "Combination 33: (StandardScaler(), KNeighborsClassifier()) - Profit Sum: -65334.88668127528 - Profit ratio: -0.41351194102072963\n",
      "Classification Report for Combination 33:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.11      0.13      0.12        68\n",
      "          -2       0.09      0.12      0.10       116\n",
      "          -1       0.19      0.26      0.22       274\n",
      "           0       0.27      0.36      0.31       401\n",
      "           1       0.22      0.16      0.18       348\n",
      "           2       0.17      0.10      0.13       174\n",
      "           3       0.12      0.06      0.08        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.20      1580\n",
      "   macro avg       0.08      0.08      0.08      1580\n",
      "weighted avg       0.19      0.20      0.19      1580\n",
      "\n",
      "\n",
      "0    965\n",
      "1    615\n",
      "Name: True_False, dtype: int64\n",
      "965\n",
      "615\n",
      "Combination 34: (StandardScaler(), KNeighborsClassifier(n_neighbors=7)) - Profit Sum: -67924.0434600738 - Profit ratio: -0.42989900924097335\n",
      "Classification Report for Combination 34:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.09      0.06      0.07        68\n",
      "          -2       0.08      0.09      0.09       116\n",
      "          -1       0.22      0.31      0.26       274\n",
      "           0       0.28      0.42      0.33       401\n",
      "           1       0.24      0.18      0.20       348\n",
      "           2       0.16      0.10      0.12       174\n",
      "           3       0.12      0.03      0.05        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.22      1580\n",
      "   macro avg       0.08      0.08      0.08      1580\n",
      "weighted avg       0.20      0.22      0.20      1580\n",
      "\n",
      "\n",
      "0    955\n",
      "1    625\n",
      "Name: True_False, dtype: int64\n",
      "955\n",
      "625\n",
      "Combination 35: (StandardScaler(), GaussianNB(var_smoothing=0.1)) - Profit Sum: -71700.73221527421 - Profit ratio: -0.4538021026283178\n",
      "Classification Report for Combination 35:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.04      0.14      0.06         7\n",
      "          -4       0.04      0.16      0.06        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.12      0.09      0.10       116\n",
      "          -1       0.24      0.19      0.21       274\n",
      "           0       0.28      0.55      0.37       401\n",
      "           1       0.22      0.04      0.06       348\n",
      "           2       0.23      0.13      0.16       174\n",
      "           3       0.16      0.09      0.12        87\n",
      "           4       0.10      0.01      0.03        68\n",
      "           5       0.04      0.20      0.07        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.21      1580\n",
      "   macro avg       0.09      0.10      0.08      1580\n",
      "weighted avg       0.21      0.21      0.18      1580\n",
      "\n",
      "\n",
      "0    891\n",
      "1    689\n",
      "Name: True_False, dtype: int64\n",
      "891\n",
      "689\n",
      "Combination 36: (StandardScaler(), GaussianNB(var_smoothing=0.01)) - Profit Sum: -70075.05678465843 - Profit ratio: -0.44351301762442047\n",
      "Classification Report for Combination 36:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.03      0.14      0.05         7\n",
      "          -4       0.04      0.16      0.06        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.10      0.09      0.09       116\n",
      "          -1       0.22      0.18      0.20       274\n",
      "           0       0.28      0.54      0.37       401\n",
      "           1       0.27      0.05      0.08       348\n",
      "           2       0.24      0.13      0.17       174\n",
      "           3       0.17      0.11      0.14        87\n",
      "           4       0.12      0.03      0.05        68\n",
      "           5       0.04      0.20      0.06        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.21      1580\n",
      "   macro avg       0.09      0.10      0.08      1580\n",
      "weighted avg       0.22      0.21      0.18      1580\n",
      "\n",
      "\n",
      "0    881\n",
      "1    699\n",
      "Name: True_False, dtype: int64\n",
      "881\n",
      "699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 37: (StandardScaler(), LogisticRegression(C=0.1)) - Profit Sum: -95199.74628353975 - Profit ratio: -0.6025300397692389\n",
      "Classification Report for Combination 37:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.07      0.03      0.05       116\n",
      "          -1       0.20      0.09      0.13       274\n",
      "           0       0.27      0.83      0.41       401\n",
      "           1       0.28      0.08      0.12       348\n",
      "           2       0.17      0.08      0.11       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      1580\n",
      "   macro avg       0.07      0.07      0.05      1580\n",
      "weighted avg       0.19      0.26      0.17      1580\n",
      "\n",
      "\n",
      "0    1008\n",
      "1     572\n",
      "Name: True_False, dtype: int64\n",
      "1008\n",
      "572\n",
      "Combination 38: (StandardScaler(), LogisticRegression(C=0.01)) - Profit Sum: -97912.36003865078 - Profit ratio: -0.6196984812572834\n",
      "Classification Report for Combination 38:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.08      0.03      0.04       116\n",
      "          -1       0.19      0.09      0.12       274\n",
      "           0       0.27      0.84      0.41       401\n",
      "           1       0.26      0.07      0.11       348\n",
      "           2       0.19      0.08      0.11       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.07      0.07      0.05      1580\n",
      "weighted avg       0.18      0.25      0.16      1580\n",
      "\n",
      "\n",
      "0    1025\n",
      "1     555\n",
      "Name: True_False, dtype: int64\n",
      "1025\n",
      "555\n",
      "Combination 39: (RobustScaler(), KNeighborsClassifier(n_neighbors=3)) - Profit Sum: -60767.44924939303 - Profit ratio: -0.3846041091733736\n",
      "Classification Report for Combination 39:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.10      0.21      0.13        68\n",
      "          -2       0.08      0.18      0.11       116\n",
      "          -1       0.20      0.28      0.23       274\n",
      "           0       0.27      0.31      0.28       401\n",
      "           1       0.27      0.15      0.19       348\n",
      "           2       0.17      0.06      0.09       174\n",
      "           3       0.06      0.01      0.02        87\n",
      "           4       0.17      0.01      0.03        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.19      1580\n",
      "   macro avg       0.09      0.08      0.07      1580\n",
      "weighted avg       0.20      0.19      0.18      1580\n",
      "\n",
      "\n",
      "0    983\n",
      "1    597\n",
      "Name: True_False, dtype: int64\n",
      "983\n",
      "597\n",
      "Combination 40: (RobustScaler(), DecisionTreeClassifier(max_depth=5)) - Profit Sum: -87356.48472023863 - Profit ratio: -0.5528891437989787\n",
      "Classification Report for Combination 40:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.09      0.02      0.03       116\n",
      "          -1       0.25      0.31      0.28       274\n",
      "           0       0.26      0.65      0.37       401\n",
      "           1       0.28      0.09      0.13       348\n",
      "           2       0.17      0.10      0.12       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.07      0.08      0.06      1580\n",
      "weighted avg       0.20      0.25      0.19      1580\n",
      "\n",
      "\n",
      "0    990\n",
      "1    590\n",
      "Name: True_False, dtype: int64\n",
      "990\n",
      "590\n",
      "Combination 41: (RobustScaler(), GaussianNB()) - Profit Sum: -70174.94093232686 - Profit ratio: -0.4441451957742206\n",
      "Classification Report for Combination 41:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.03      0.14      0.05         7\n",
      "          -4       0.04      0.16      0.06        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.10      0.09      0.10       116\n",
      "          -1       0.22      0.18      0.20       274\n",
      "           0       0.28      0.54      0.37       401\n",
      "           1       0.27      0.05      0.08       348\n",
      "           2       0.24      0.13      0.17       174\n",
      "           3       0.16      0.11      0.14        87\n",
      "           4       0.11      0.03      0.05        68\n",
      "           5       0.04      0.20      0.06        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.21      1580\n",
      "   macro avg       0.09      0.10      0.08      1580\n",
      "weighted avg       0.22      0.21      0.18      1580\n",
      "\n",
      "\n",
      "0    882\n",
      "1    698\n",
      "Name: True_False, dtype: int64\n",
      "882\n",
      "698\n",
      "Combination 42: (RobustScaler(), RandomForestClassifier(max_depth=5, n_estimators=300)) - Profit Sum: -94491.5841651003 - Profit ratio: -0.5980480010449386\n",
      "Classification Report for Combination 42:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.06      0.01      0.02       116\n",
      "          -1       0.24      0.18      0.20       274\n",
      "           0       0.27      0.79      0.40       401\n",
      "           1       0.33      0.09      0.14       348\n",
      "           2       0.15      0.07      0.10       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      1580\n",
      "   macro avg       0.07      0.08      0.06      1580\n",
      "weighted avg       0.20      0.26      0.18      1580\n",
      "\n",
      "\n",
      "0    1004\n",
      "1     576\n",
      "Name: True_False, dtype: int64\n",
      "1004\n",
      "576\n",
      "Combination 43: (RobustScaler(), AdaBoostClassifier(learning_rate=0.1)) - Profit Sum: -101535.80176127196 - Profit ratio: -0.6426316567169111\n",
      "Classification Report for Combination 43:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.31      0.07      0.11       274\n",
      "           0       0.27      0.87      0.41       401\n",
      "           1       0.30      0.16      0.21       348\n",
      "           2       0.06      0.01      0.01       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.27      1580\n",
      "   macro avg       0.06      0.07      0.05      1580\n",
      "weighted avg       0.19      0.27      0.17      1580\n",
      "\n",
      "\n",
      "0    1048\n",
      "1     532\n",
      "Name: True_False, dtype: int64\n",
      "1048\n",
      "532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 44: (RobustScaler(), LogisticRegression()) - Profit Sum: -95030.29004981084 - Profit ratio: -0.6014575319608281\n",
      "Classification Report for Combination 44:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.10      0.07      0.08       116\n",
      "          -1       0.19      0.08      0.12       274\n",
      "           0       0.27      0.80      0.41       401\n",
      "           1       0.25      0.07      0.12       348\n",
      "           2       0.17      0.09      0.12       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.07      0.07      0.06      1580\n",
      "weighted avg       0.18      0.25      0.17      1580\n",
      "\n",
      "\n",
      "0    1011\n",
      "1     569\n",
      "Name: True_False, dtype: int64\n",
      "1011\n",
      "569\n",
      "Combination 45: (RobustScaler(), MLPClassifier(hidden_layer_sizes=(10, 5), learning_rate_init=0.01)) - Profit Sum: -78830.28806328465 - Profit ratio: -0.49892587381825726\n",
      "Classification Report for Combination 45:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.20      0.02      0.03       116\n",
      "          -1       0.23      0.31      0.27       274\n",
      "           0       0.27      0.59      0.37       401\n",
      "           1       0.29      0.14      0.19       348\n",
      "           2       0.16      0.14      0.15       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.08      0.08      0.07      1580\n",
      "weighted avg       0.21      0.25      0.20      1580\n",
      "\n",
      "\n",
      "0    938\n",
      "1    642\n",
      "Name: True_False, dtype: int64\n",
      "938\n",
      "642\n",
      "Combination 46: (RobustScaler(), MLPClassifier(hidden_layer_sizes=(20, 10))) - Profit Sum: -80928.7354050927 - Profit ratio: -0.5122071861081816\n",
      "Classification Report for Combination 46:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.16      0.08      0.10       116\n",
      "          -1       0.24      0.16      0.19       274\n",
      "           0       0.28      0.67      0.40       401\n",
      "           1       0.26      0.19      0.22       348\n",
      "           2       0.20      0.13      0.15       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      1580\n",
      "   macro avg       0.08      0.08      0.07      1580\n",
      "weighted avg       0.20      0.26      0.21      1580\n",
      "\n",
      "\n",
      "0    941\n",
      "1    639\n",
      "Name: True_False, dtype: int64\n",
      "941\n",
      "639\n",
      "Combination 47: (RobustScaler(), MLPClassifier(hidden_layer_sizes=(50, 25), learning_rate_init=0.0001)) - Profit Sum: -92975.89801233503 - Profit ratio: -0.5884550507109813\n",
      "Classification Report for Combination 47:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.25      0.01      0.03        68\n",
      "          -2       0.10      0.07      0.08       116\n",
      "          -1       0.26      0.14      0.18       274\n",
      "           0       0.26      0.74      0.39       401\n",
      "           1       0.22      0.09      0.13       348\n",
      "           2       0.18      0.09      0.12       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       1.00      0.01      0.03        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.15      0.08      0.06      1580\n",
      "weighted avg       0.24      0.25      0.18      1580\n",
      "\n",
      "\n",
      "0    1008\n",
      "1     572\n",
      "Name: True_False, dtype: int64\n",
      "1008\n",
      "572\n",
      "Combination 48: (RobustScaler(), RandomForestClassifier(max_depth=10, n_estimators=500)) - Profit Sum: -91967.4953189855 - Profit ratio: -0.5820727551834526\n",
      "Classification Report for Combination 48:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.06      0.02      0.03       116\n",
      "          -1       0.25      0.19      0.22       274\n",
      "           0       0.26      0.72      0.38       401\n",
      "           1       0.31      0.11      0.17       348\n",
      "           2       0.20      0.09      0.12       174\n",
      "           3       0.08      0.01      0.02        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.08      0.08      0.06      1580\n",
      "weighted avg       0.21      0.25      0.19      1580\n",
      "\n",
      "\n",
      "0    1010\n",
      "1     570\n",
      "Name: True_False, dtype: int64\n",
      "1010\n",
      "570\n",
      "Combination 49: (RobustScaler(), RandomForestClassifier(max_depth=20, n_estimators=1000)) - Profit Sum: -83417.0842833191 - Profit ratio: -0.5279562296412601\n",
      "Classification Report for Combination 49:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.33      0.05      0.09        19\n",
      "          -3       0.17      0.01      0.03        68\n",
      "          -2       0.10      0.05      0.07       116\n",
      "          -1       0.24      0.21      0.22       274\n",
      "           0       0.25      0.59      0.35       401\n",
      "           1       0.25      0.15      0.19       348\n",
      "           2       0.18      0.11      0.13       174\n",
      "           3       0.09      0.02      0.04        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.24      1580\n",
      "   macro avg       0.11      0.08      0.07      1580\n",
      "weighted avg       0.20      0.24      0.19      1580\n",
      "\n",
      "\n",
      "0    987\n",
      "1    593\n",
      "Name: True_False, dtype: int64\n",
      "987\n",
      "593\n",
      "Combination 50: (RobustScaler(), AdaBoostClassifier(learning_rate=0.01, n_estimators=100)) - Profit Sum: -117900.0 - Profit ratio: -0.7462025316455696\n",
      "Classification Report for Combination 50:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.00      0.00      0.00       274\n",
      "           0       0.25      1.00      0.40       401\n",
      "           1       0.00      0.00      0.00       348\n",
      "           2       0.00      0.00      0.00       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25      1580\n",
      "   macro avg       0.02      0.07      0.03      1580\n",
      "weighted avg       0.06      0.25      0.10      1580\n",
      "\n",
      "\n",
      "0    1179\n",
      "1     401\n",
      "Name: True_False, dtype: int64\n",
      "1179\n",
      "401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 51: (RobustScaler(), AdaBoostClassifier(learning_rate=0.1, n_estimators=500)) - Profit Sum: -86981.92792325743 - Profit ratio: -0.5505185311598572\n",
      "Classification Report for Combination 51:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.23      0.18      0.20       274\n",
      "           0       0.27      0.69      0.39       401\n",
      "           1       0.23      0.04      0.06       348\n",
      "           2       0.16      0.14      0.15       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.12      0.01      0.03        68\n",
      "           5       0.07      0.30      0.11        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.23      1580\n",
      "   macro avg       0.07      0.08      0.06      1580\n",
      "weighted avg       0.18      0.23      0.17      1580\n",
      "\n",
      "\n",
      "0    961\n",
      "1    619\n",
      "Name: True_False, dtype: int64\n",
      "961\n",
      "619\n",
      "Combination 52: (RobustScaler(), KNeighborsClassifier()) - Profit Sum: -61957.53894436589 - Profit ratio: -0.3921363224326955\n",
      "Classification Report for Combination 52:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.11      0.11      0.11        19\n",
      "          -3       0.04      0.04      0.04        68\n",
      "          -2       0.11      0.14      0.12       116\n",
      "          -1       0.21      0.28      0.24       274\n",
      "           0       0.28      0.39      0.32       401\n",
      "           1       0.25      0.17      0.20       348\n",
      "           2       0.21      0.13      0.16       174\n",
      "           3       0.06      0.02      0.03        87\n",
      "           4       0.08      0.01      0.03        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.22      1580\n",
      "   macro avg       0.09      0.09      0.08      1580\n",
      "weighted avg       0.20      0.22      0.20      1580\n",
      "\n",
      "\n",
      "0    945\n",
      "1    635\n",
      "Name: True_False, dtype: int64\n",
      "945\n",
      "635\n",
      "Combination 53: (RobustScaler(), KNeighborsClassifier(n_neighbors=7)) - Profit Sum: -70056.90005793866 - Profit ratio: -0.4433981016325232\n",
      "Classification Report for Combination 53:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.02      0.01      0.02        68\n",
      "          -2       0.10      0.13      0.11       116\n",
      "          -1       0.22      0.29      0.25       274\n",
      "           0       0.28      0.46      0.35       401\n",
      "           1       0.26      0.18      0.22       348\n",
      "           2       0.17      0.10      0.13       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.23      1580\n",
      "   macro avg       0.07      0.08      0.07      1580\n",
      "weighted avg       0.20      0.23      0.20      1580\n",
      "\n",
      "\n",
      "0    962\n",
      "1    618\n",
      "Name: True_False, dtype: int64\n",
      "962\n",
      "618\n",
      "Combination 54: (RobustScaler(), GaussianNB(var_smoothing=0.1)) - Profit Sum: -116526.40979055865 - Profit ratio: -0.7375089227250547\n",
      "Classification Report for Combination 54:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.00      0.00      0.00       116\n",
      "          -1       0.00      0.00      0.00       274\n",
      "           0       0.26      1.00      0.41       401\n",
      "           1       0.00      0.00      0.00       348\n",
      "           2       0.29      0.02      0.04       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      1580\n",
      "   macro avg       0.04      0.07      0.03      1580\n",
      "weighted avg       0.10      0.26      0.11      1580\n",
      "\n",
      "\n",
      "0    1166\n",
      "1     414\n",
      "Name: True_False, dtype: int64\n",
      "1166\n",
      "414\n",
      "Combination 55: (RobustScaler(), GaussianNB(var_smoothing=0.01)) - Profit Sum: -86223.74884569776 - Profit ratio: -0.5457199294031504\n",
      "Classification Report for Combination 55:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -8       0.00      0.00      0.00         0\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.15      0.06      0.09       116\n",
      "          -1       0.28      0.15      0.19       274\n",
      "           0       0.27      0.74      0.40       401\n",
      "           1       0.23      0.03      0.05       348\n",
      "           2       0.17      0.11      0.13       174\n",
      "           3       0.14      0.01      0.02        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.07      0.10      0.08        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.24      1580\n",
      "   macro avg       0.08      0.07      0.06      1580\n",
      "weighted avg       0.21      0.24      0.17      1580\n",
      "\n",
      "\n",
      "0    965\n",
      "1    615\n",
      "Name: True_False, dtype: int64\n",
      "965\n",
      "615\n",
      "Combination 56: (RobustScaler(), LogisticRegression(C=0.1)) - Profit Sum: -94216.34878587475 - Profit ratio: -0.5963060049738909\n",
      "Classification Report for Combination 56:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.11      0.07      0.08       116\n",
      "          -1       0.20      0.09      0.12       274\n",
      "           0       0.27      0.82      0.41       401\n",
      "           1       0.31      0.08      0.13       348\n",
      "           2       0.18      0.10      0.13       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      1580\n",
      "   macro avg       0.07      0.08      0.06      1580\n",
      "weighted avg       0.20      0.26      0.17      1580\n",
      "\n",
      "\n",
      "0    1003\n",
      "1     577\n",
      "Name: True_False, dtype: int64\n",
      "1003\n",
      "577\n",
      "Combination 57: (RobustScaler(), LogisticRegression(C=0.01)) - Profit Sum: -97426.2986927157 - Profit ratio: -0.616622143624783\n",
      "Classification Report for Combination 57:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         2\n",
      "          -6       0.00      0.00      0.00         3\n",
      "          -5       0.00      0.00      0.00         7\n",
      "          -4       0.00      0.00      0.00        19\n",
      "          -3       0.00      0.00      0.00        68\n",
      "          -2       0.07      0.03      0.04       116\n",
      "          -1       0.23      0.10      0.14       274\n",
      "           0       0.27      0.85      0.41       401\n",
      "           1       0.29      0.08      0.13       348\n",
      "           2       0.17      0.06      0.09       174\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        68\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      1580\n",
      "   macro avg       0.07      0.07      0.05      1580\n",
      "weighted avg       0.20      0.26      0.17      1580\n",
      "\n",
      "\n",
      "0    1021\n",
      "1     559\n",
      "Name: True_False, dtype: int64\n",
      "1021\n",
      "559\n"
     ]
    }
   ],
   "source": [
    "profit_sums_c,clas_report_c=train_model_win_lose(step10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
